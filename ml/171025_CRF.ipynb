{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://gist.github.com/5904067e7e7e3d18ecec3d1c14f8f427\n"
     ]
    }
   ],
   "source": [
    "# Don't care. It's just a command for gist update.\n",
    "run(`gist -u https://gist.github.com/5904067e7e7e3d18ecec3d1c14f8f427 CRF_slides.ipynb`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "You can access this notebook from [here](http://nbviewer.jupyter.org/gist/KeitaW/5904067e7e7e3d18ecec3d1c14f8f427)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "$$\n",
    "\\newcommand{\\argmax}{\\mathop{\\rm arg~max}\\limits}\n",
    "\\newcommand{\\argmin}{\\mathop{\\rm arg~min}\\limits}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.4 条件つき確率場（Conditional ramdom fields）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using Iterators.Iterators in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "using PyCall\n",
    "using DataFrames\n",
    "using ScikitLearn\n",
    "using Base.Test\n",
    "using Base.Iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_tagged_dataset (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pyimport nltk.corpus as corpus\n",
    "function load_tagged_dataset(;ndata=Int(1e+06))\n",
    "    tagged_words = corpus.brown[:tagged_words]()\n",
    "    sentences = []; tags_list = []\n",
    "    words = []; tags = []\n",
    "    for (word, tag) in tagged_words\n",
    "        if word == \".\"\n",
    "            # Separate sentence by \".\"\n",
    "            push!(sentences, words); push!(tags_list, tags)\n",
    "            words = []; tags = []\n",
    "        else\n",
    "            push!(words, lowercase.(word)); push!(tags, tag)\n",
    "        end\n",
    "    end\n",
    "    return DataFrame(\n",
    "        sentences = sentences,\n",
    "        tags_list = tags_list)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>sentences</th><th>tags_list</th></tr></thead><tbody><tr><th>1</th><td>Any[\"the\", \"fulton\", \"county\", \"grand\", \"jury\", \"said\", \"friday\", \"an\", \"investigation\", \"of\", \"atlanta's\", \"recent\", \"primary\", \"election\", \"produced\", \"``\", \"no\", \"evidence\", \"''\", \"that\", \"any\", \"irregularities\", \"took\", \"place\"]</td><td>Any[\"AT\", \"NP-TL\", \"NN-TL\", \"JJ-TL\", \"NN-TL\", \"VBD\", \"NR\", \"AT\", \"NN\", \"IN\", \"NP\\$\", \"JJ\", \"NN\", \"NN\", \"VBD\", \"``\", \"AT\", \"NN\", \"''\", \"CS\", \"DTI\", \"NNS\", \"VBD\", \"NN\"]</td></tr><tr><th>2</th><td>Any[\"the\", \"jury\", \"further\", \"said\", \"in\", \"term-end\", \"presentments\", \"that\", \"the\", \"city\", \"executive\", \"committee\", \",\", \"which\", \"had\", \"over-all\", \"charge\", \"of\", \"the\", \"election\", \",\", \"``\", \"deserves\", \"the\", \"praise\", \"and\", \"thanks\", \"of\", \"the\", \"city\", \"of\", \"atlanta\", \"''\", \"for\", \"the\", \"manner\", \"in\", \"which\", \"the\", \"election\", \"was\", \"conducted\"]</td><td>Any[\"AT\", \"NN\", \"RBR\", \"VBD\", \"IN\", \"NN\", \"NNS\", \"CS\", \"AT\", \"NN-TL\", \"JJ-TL\", \"NN-TL\", \",\", \"WDT\", \"HVD\", \"JJ\", \"NN\", \"IN\", \"AT\", \"NN\", \",\", \"``\", \"VBZ\", \"AT\", \"NN\", \"CC\", \"NNS\", \"IN\", \"AT\", \"NN-TL\", \"IN-TL\", \"NP-TL\", \"''\", \"IN\", \"AT\", \"NN\", \"IN\", \"WDT\", \"AT\", \"NN\", \"BEDZ\", \"VBN\"]</td></tr><tr><th>3</th><td>Any[\"the\", \"september-october\", \"term\", \"jury\", \"had\", \"been\", \"charged\", \"by\", \"fulton\", \"superior\", \"court\", \"judge\", \"durwood\", \"pye\", \"to\", \"investigate\", \"reports\", \"of\", \"possible\", \"``\", \"irregularities\", \"''\", \"in\", \"the\", \"hard-fought\", \"primary\", \"which\", \"was\", \"won\", \"by\", \"mayor-nominate\", \"ivan\", \"allen\", \"jr.\"]</td><td>Any[\"AT\", \"NP\", \"NN\", \"NN\", \"HVD\", \"BEN\", \"VBN\", \"IN\", \"NP-TL\", \"JJ-TL\", \"NN-TL\", \"NN-TL\", \"NP\", \"NP\", \"TO\", \"VB\", \"NNS\", \"IN\", \"JJ\", \"``\", \"NNS\", \"''\", \"IN\", \"AT\", \"JJ\", \"NN\", \"WDT\", \"BEDZ\", \"VBN\", \"IN\", \"NN-TL\", \"NP\", \"NP\", \"NP\"]</td></tr><tr><th>4</th><td>Any[\"``\", \"only\", \"a\", \"relative\", \"handful\", \"of\", \"such\", \"reports\", \"was\", \"received\", \"''\", \",\", \"the\", \"jury\", \"said\", \",\", \"``\", \"considering\", \"the\", \"widespread\", \"interest\", \"in\", \"the\", \"election\", \",\", \"the\", \"number\", \"of\", \"voters\", \"and\", \"the\", \"size\", \"of\", \"this\", \"city\", \"''\"]</td><td>Any[\"``\", \"RB\", \"AT\", \"JJ\", \"NN\", \"IN\", \"JJ\", \"NNS\", \"BEDZ\", \"VBN\", \"''\", \",\", \"AT\", \"NN\", \"VBD\", \",\", \"``\", \"IN\", \"AT\", \"JJ\", \"NN\", \"IN\", \"AT\", \"NN\", \",\", \"AT\", \"NN\", \"IN\", \"NNS\", \"CC\", \"AT\", \"NN\", \"IN\", \"DT\", \"NN\", \"''\"]</td></tr><tr><th>5</th><td>Any[\"the\", \"jury\", \"said\", \"it\", \"did\", \"find\", \"that\", \"many\", \"of\", \"georgia's\", \"registration\", \"and\", \"election\", \"laws\", \"``\", \"are\", \"outmoded\", \"or\", \"inadequate\", \"and\", \"often\", \"ambiguous\", \"''\"]</td><td>Any[\"AT\", \"NN\", \"VBD\", \"PPS\", \"DOD\", \"VB\", \"CS\", \"AP\", \"IN\", \"NP\\$\", \"NN\", \"CC\", \"NN\", \"NNS\", \"``\", \"BER\", \"JJ\", \"CC\", \"JJ\", \"CC\", \"RB\", \"JJ\", \"''\"]</td></tr><tr><th>6</th><td>Any[\"it\", \"recommended\", \"that\", \"fulton\", \"legislators\", \"act\", \"``\", \"to\", \"have\", \"these\", \"laws\", \"studied\", \"and\", \"revised\", \"to\", \"the\", \"end\", \"of\", \"modernizing\", \"and\", \"improving\", \"them\", \"''\"]</td><td>Any[\"PPS\", \"VBD\", \"CS\", \"NP\", \"NNS\", \"VB\", \"``\", \"TO\", \"HV\", \"DTS\", \"NNS\", \"VBN\", \"CC\", \"VBN\", \"IN\", \"AT\", \"NN\", \"IN\", \"VBG\", \"CC\", \"VBG\", \"PPO\", \"''\"]</td></tr></tbody></table>"
      ],
      "text/plain": [
       "6×2 DataFrames.DataFrame\n",
       "│ Row │ ├─────┼\n",
       "│ 1   │ │ 2   │ │ 3   │ │ 4   │ │ 5   │ │ 6   │ \n",
       "\n",
       "│ Row │ sentences                                                                                                                                                                                                                                                                                                                                                                       │\n",
       "├─────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ 1   │ Any[\"the\", \"fulton\", \"county\", \"grand\", \"jury\", \"said\", \"friday\", \"an\", \"investigation\", \"of\"  …  \"produced\", \"``\", \"no\", \"evidence\", \"''\", \"that\", \"any\", \"irregularities\", \"took\", \"place\"]                                                                                                                                        │\n",
       "│ 2   │ Any[\"the\", \"jury\", \"further\", \"said\", \"in\", \"term-end\", \"presentments\", \"that\", \"the\", \"city\"  …  \"''\", \"for\", \"the\", \"manner\", \"in\", \"which\", \"the\", \"election\", \"was\", \"conducted\"] │\n",
       "│ 3   │ Any[\"the\", \"september-october\", \"term\", \"jury\", \"had\", \"been\", \"charged\", \"by\", \"fulton\", \"superior\"  …  \"hard-fought\", \"primary\", \"which\", \"was\", \"won\", \"by\", \"mayor-nominate\", \"ivan\", \"allen\", \"jr.\"]                                         │\n",
       "│ 4   │ Any[\"``\", \"only\", \"a\", \"relative\", \"handful\", \"of\", \"such\", \"reports\", \"was\", \"received\"  …  \"number\", \"of\", \"voters\", \"and\", \"the\", \"size\", \"of\", \"this\", \"city\", \"''\"]                                                                         │\n",
       "│ 5   │ Any[\"the\", \"jury\", \"said\", \"it\", \"did\", \"find\", \"that\", \"many\", \"of\", \"georgia's\"  …  \"laws\", \"``\", \"are\", \"outmoded\", \"or\", \"inadequate\", \"and\", \"often\", \"ambiguous\", \"''\"]                                                                                                                                                                   │\n",
       "│ 6   │ Any[\"it\", \"recommended\", \"that\", \"fulton\", \"legislators\", \"act\", \"``\", \"to\", \"have\", \"these\"  …  \"revised\", \"to\", \"the\", \"end\", \"of\", \"modernizing\", \"and\", \"improving\", \"them\", \"''\"]                                                                                                                                                                   │\n",
       "\n",
       "│ Row │ tags_list                                                                                                                                                                                                                                                                                  │\n",
       "├─────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ 1   │ Any[\"AT\", \"NP-TL\", \"NN-TL\", \"JJ-TL\", \"NN-TL\", \"VBD\", \"NR\", \"AT\", \"NN\", \"IN\"  …  \"VBD\", \"``\", \"AT\", \"NN\", \"''\", \"CS\", \"DTI\", \"NNS\", \"VBD\", \"NN\"]                                                                                                                     │\n",
       "│ 2   │ Any[\"AT\", \"NN\", \"RBR\", \"VBD\", \"IN\", \"NN\", \"NNS\", \"CS\", \"AT\", \"NN-TL\"  …  \"''\", \"IN\", \"AT\", \"NN\", \"IN\", \"WDT\", \"AT\", \"NN\", \"BEDZ\", \"VBN\"] │\n",
       "│ 3   │ Any[\"AT\", \"NP\", \"NN\", \"NN\", \"HVD\", \"BEN\", \"VBN\", \"IN\", \"NP-TL\", \"JJ-TL\"  …  \"JJ\", \"NN\", \"WDT\", \"BEDZ\", \"VBN\", \"IN\", \"NN-TL\", \"NP\", \"NP\", \"NP\"]                                                    │\n",
       "│ 4   │ Any[\"``\", \"RB\", \"AT\", \"JJ\", \"NN\", \"IN\", \"JJ\", \"NNS\", \"BEDZ\", \"VBN\"  …  \"NN\", \"IN\", \"NNS\", \"CC\", \"AT\", \"NN\", \"IN\", \"DT\", \"NN\", \"''\"]                                                             │\n",
       "│ 5   │ Any[\"AT\", \"NN\", \"VBD\", \"PPS\", \"DOD\", \"VB\", \"CS\", \"AP\", \"IN\", \"NP\\$\"  …  \"NNS\", \"``\", \"BER\", \"JJ\", \"CC\", \"JJ\", \"CC\", \"RB\", \"JJ\", \"''\"]                                                                                                                                       │\n",
       "│ 6   │ Any[\"PPS\", \"VBD\", \"CS\", \"NP\", \"NNS\", \"VB\", \"``\", \"TO\", \"HV\", \"DTS\"  …  \"VBN\", \"IN\", \"AT\", \"NN\", \"IN\", \"VBG\", \"CC\", \"VBG\", \"PPO\", \"''\"]                                                                                                                                    │"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_words_org = load_tagged_dataset()\n",
    "head(tagged_words_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{String,1}:\n",
       " \"along\"   \n",
       " \"with\"    \n",
       " \"a\"       \n",
       " \"director\"\n",
       " \",\"       \n",
       " \"the\"     \n",
       " \"city\"    \n",
       " \"should\"  \n",
       " \"provide\" \n",
       " \"a\"       "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: both ScikitLearn and DataFrames export \"fit!\"; uses of it in module Main must be qualified\n",
      "WARNING: both ScikitLearn and DataFrames export \"predict\"; uses of it in module Main must be qualified\n",
      "WARNING: both ScikitLearn and DataFrames export \"sample\"; uses of it in module Main must be qualified\n"
     ]
    }
   ],
   "source": [
    "numdata = Int(1e+03)\n",
    "tagged_words = tagged_words_org[1:numdata, :]\n",
    "X_train, X_test, y_train, y_test = ScikitLearn.CrossValidation.train_test_split(tagged_words[:sentences], tagged_words[:tags_list], test_size = 0.3);\n",
    "X_train_, X_test_, y_train_, y_test_ =  collect(flatten(X_train)), collect(flatten(X_test)), collect(flatten(y_train)), collect(flatten(y_test));\n",
    "X_train_[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Omake: small code for making one hot vector of your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "word2int = (uniq_words) -> Dict(word => i for (i, word) in enumerate(uniq_words));\n",
    "int2word = (uniq_words) -> Dict(i => word for (i, word) in enumerate(uniq_words));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m\u001b[32mTest Passed\n",
       "\u001b[39m\u001b[22m"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_onehot = (vocab_size) -> function (int)\n",
    "    onehotvec = zeros(vocab_size)\n",
    "    onehotvec[int] = 1\n",
    "    return onehotvec\n",
    "end\n",
    "@test to_onehot(3)(1) == [1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m\u001b[32mTest Passed\n",
       "\u001b[39m\u001b[22m"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_onehot_data = (wordint_dict) -> function (words)\n",
    "    vocab_size = length(wordint_dict); data_size = length(words)\n",
    "    onehot_data = zeros(vocab_size, data_size) # each column corresponds to one data as julia stores elements in column-major order\n",
    "    onehot_vec = to_one_hot(vocab_size) \n",
    "    for (col, word) in enumerate(words) onehot_data[:, col] = onehot_vec(wordint_dict[word]) end\n",
    "    return(onehot_data)\n",
    "end\n",
    "test_data = [\"a\", \"b\", \"c\", \"d\"]; test_x = [\"a\", \"b\", \"c\"]; test_y = [\"d\"]\n",
    "wordint_dict = test_data |> word2int\n",
    "to_onehot_data(wordint_dict)(test_x)\n",
    "@test to_onehot_data(wordint_dict)(test_x) == [1 0 0; 0 1 0; 0 0 1; 0 0 0]\n",
    "@test to_onehot_data(wordint_dict)(test_y) == [0 0 0 1]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length(uniq_words) = 4926\n"
     ]
    }
   ],
   "source": [
    "uniq_words = tagged_words[:sentences] |> flatten |> collect |> unique\n",
    "@show length(uniq_words);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "wordint_dict = t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let $D = \\{ (\\mathbf{x}^{(1)}, \\mathbf{y}^{(1)}), (\\mathbf{x}^{(2)}, \\mathbf{y}^{(2)}), \\dots, (\\mathbf{x}^{(T)}, \\mathbf{y}^{(T)})\\}$ be training dataset where,\n",
    "* $\\mathbf{x}$: Data (In this context, it's words),\n",
    "* $\\mathbf{y}$: Label (In this context, it's tags)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "CRF is a kind of log linear model, thus conditional probability $P(\\mathbf{y}\\mid \\mathbf{x})$ is defined as follows,\n",
    "$$\n",
    "P(\\mathbf{y}\\mid \\mathbf{x}) = \\frac{1}{Z_{\\mathbf{x}, \\mathbf{w}}} \\exp (\\mathbf{w}\\cdot \\mathbf{\\phi}(\\mathbf{x}, \\mathbf{y})) \\\\\n",
    "= \\frac{\\exp (\\mathbf{w}\\cdot \\mathbf{\\phi}(\\mathbf{x}, \\mathbf{y}))}{\\sum_{\\mathbf{y}}\\exp (\\mathbf{w}\\cdot \\mathbf{\\phi}(\\mathbf{x}, \\mathbf{y}))} \n",
    "$$\n",
    "where $\\mathbf{\\phi}(\\mathbf{x}, \\mathbf{y}) = (\\sum_t \\phi_1(\\mathbf{x}, y_t, y_{t-1}), \\sum_t \\phi_2(\\mathbf{x}, y_t, y_{t-1}) \\dots, \\sum_t \\phi_k(\\mathbf{x}, y_t, y_{t-1}), \\dots, \\sum_t \\phi_F(\\mathbf{x}, y_t, y_{t-1}))^{\\mathbf{T}}$ and $F$ be the number of dimensions of our feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Thus, we could evaluate the optimal tag assignment by solving the following problem,\n",
    "$$\n",
    "\\mathbf{y}^* = \\argmax_{\\mathbf{y}} \\frac{1}{Z_{\\mathbf{x}, \\mathbf{w}}} \\exp (\\mathbf{w}\\cdot \\mathbf{\\phi}(\\mathbf{x}, \\mathbf{y})) \\\\\n",
    "= \\argmax_{\\mathbf{y}} \\mathbf{w}\\cdot \\mathbf{\\phi}(\\mathbf{x}, \\mathbf{y}) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Here, using an assumption: $\\phi_k(\\mathbf{x}, \\mathbf{y}) = \\sum_t \\phi_k(\\mathbf{x}, y_t, y_{t-1})$ end up with,\n",
    "$$\n",
    "\\mathbf{y}^* = \\argmax_{\\mathbf{y}} \\sum_t \\mathbf{w} \\cdot \\mathbf{\\phi}(\\mathbf{x}, y_t, y_{t-1})\n",
    "$$\n",
    "You could use the Viterbi algorithm to solve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We may use the Viterbi algorithm for the estimation of $\\mathbf{y}^*$ once we get an appropriate $\\mathbf{w}$. So, how do we learn $\\mathbf{w}$? $\\rightarrow$ __the Forward-backward algorithm.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Forward-backward algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We want to maximize the likelyhood function $L(\\mathbf{w}) = \\sum_{(\\mathbf{x}^{(i)}, \\mathbf{y}^{(i)}) \\in D} \\log P(\\mathbf{y}^{(i)} \\mid \\mathbf{x}^{(i)})$. It can be accomplished by using the Gradient Descent method,\n",
    "$$\n",
    "\\mathbf{w}^{new} = \\mathbf{w}^{old} + \\epsilon \\nabla_\\mathbf{w} L(\\mathbf{w}^{old})\n",
    "$$\n",
    "But, its calculation can be very expensive as the second term of the RHS, $$\\nabla_\\mathbf{w} L(\\mathbf{w}) = \\sum_{(\\mathbf{x}^{(i)}, \\mathbf{y}^{(i)}) \\in D} \\left( \n",
    "\\mathbf{\\phi}(\\mathbf{x}^{(i)}, \\mathbf{y}^{(i)}) - \\sum_{\\mathbf{y}}P(\\mathbf{y} \\mid \\mathbf{x}^{(i)})\\mathbf{\\phi}(\\mathbf{x}^{(i)}, \\mathbf{y})\n",
    "\\right)$$\n",
    "requires calculation of every possible $P(\\mathbf{y} \\mid \\mathbf{x}^{(i)})$ in terms of  $\\mathbf{y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Using the assumption yields,\n",
    "$$\n",
    "P(\\mathbf{y} \\mid \\mathbf{x}^{(i)})\\mathbf{\\phi}(\\mathbf{x}^{(i)}, \\mathbf{y}) = \\sum_{\\mathbf{y}}P(\\mathbf{y} \\mid \\mathbf{x}) \\sum_t \\mathbf{\\phi}(\\mathbf{x}, y_t, y_{t-1}) = \\sum_t \\sum_{y_t, y_{t-1}} P(y_{t-1}, y_t \\mid \\mathbf{x})\\mathbf{\\phi}(\\mathbf{x}, y_t, y_{t-1})\n",
    "$$\n",
    "We'll discuss how to calculate $P(y_{t-1}, y_t \\mid \\mathbf{x})$ efficiently in the subsequent slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let $T$ be the length of input $\\mathbf{x}$. We define dummy labels $y_0$ and $y_{T+1}$ as $\\mathbf{B}$ and $\\mathbf{E}$ respectively.\n",
    "We denote $\\sum_{y_0, \\cdots, y_{t-2}}$ as $\\sum_{\\mathbf{y}_{0:t-2}}$ and $\\psi_t(y_t, y_{t-1})$ as $\\exp(\\mathbf{w}\\cdot \\mathbf{\\phi}(\\mathbf{x}, y_t, y_{t-1}))$ to simplify the notation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\n",
    "P(y_{t-1}, y_t \\mid \\mathbf{x}) = \\sum_{\\mathbf{y}_{0:t-2}} \\sum_{\\mathbf{y}_{t+1:t-2}} P(\\mathbf{y} \\mid \\mathbf{x}) \\\\\n",
    " = \\frac{1}{Z_{\\mathbf{x}, \\mathbf{w}}} \\sum_{\\mathbf{y}_{0:t-2}} \\sum_{\\mathbf{y}_{t+1:t-2}} \\prod_{t'} \\psi_{t'}(y_{t'}, y_{t'-1}) \\\\\n",
    " = \\frac{\\psi_{t'}(y_{t'}, y_{t'-1})}{Z_{\\mathbf{x}, \\mathbf{w}}} \\sum_{\\mathbf{y}_{0:t-2}} \\sum_{\\mathbf{y}_{t+1:t-2}} \\prod_{t'\\neq t} \\psi_{t'}(y_{t'}, y_{t'-1}) \\\\\n",
    " = \\frac{\\psi_{t'}(y_{t'}, y_{t'-1})}{Z_{\\mathbf{x}, \\mathbf{w}}} \\left(\\sum_{\\mathbf{y}_{0:t-2}} \\prod_{t'=1}^{t-1} \\psi_{t'}(y_{t'}, y_{t'-1}) \\right) \\left(\\sum_{\\mathbf{y}_{t+1:t-2}} \\prod_{t'= t+1}^{T} \\psi_{t'}(y_{t'}, y_{t'-1})\\right) \\\\\n",
    " = \\frac{\\psi_{t'}(y_{t'}, y_{t'-1})}{Z_{\\mathbf{x}, \\mathbf{w}}} \\alpha(y_t, t)\\beta(y_t, t)\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\alpha(y_t, t) = \\sum_{\\mathbf{y}_{0:t-2}} \\prod_{t'=1}^{t-1} \\psi_{t'}(y_{t'}, y_{t'-1})\\\\\n",
    "\\beta(y_t, t) = \\sum_{\\mathbf{y}_{t+1:t-2}} \\prod_{t'= t+1}^{T} \\psi_{t'}(y_{t'}, y_{t'-1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We could calculate efficiently $\\alpha(y_t, t)$, $\\beta(y_t, t)$ because,\n",
    "$$\n",
    "\\alpha(y_t, t) = \\sum_{\\mathbf{y}_{0:t-1}} \\prod_{t'=1}^{t} \\psi_{t'}(y_{t'}, y_{t'-1}) \\\\\n",
    " = \\sum_{y_{t-1}}\\psi_{t}(y_t, y_{t-1})\\sum_{\\mathbf{y}_{0:t-2}}\\prod_{t'=1}^{t-1} \\psi_{t'}(y_{t'}, y_{t'-1}) \\\\\n",
    " =  \\sum_{y_{t-1}}\\psi_{t}(y_t, y_{t-1})\\alpha(y_{t-1}, t-1)\n",
    "$$\n",
    "$$\n",
    "\\beta(y_t, t) = \\sum_{y_{t+1}}\\psi_{t+1}(y_{t+1}, y_{t})\\beta(y_{t+1}, t+1)\n",
    "$$\n",
    "Also note that,\n",
    "$$\n",
    "Z_{\\mathbf{x}, \\mathbf{w}} = \\sum_{\\mathbf{y}}\\exp (\\mathbf{w}\\cdot \\mathbf{\\phi}(\\mathbf{x}, \\mathbf{y})) = \\sum_{\\mathbf{y}_{0, T-2}} \\prod_{t=1}^{T-1} \\psi_t(y_t, y_{t-1}) = \\sum_{y_T} \\alpha(y_T, T)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here we'll use a $F$-dimensional simple feature $\\mathbf{\\phi}(\\mathbf{x}, y_t, y_{t-1})$ which $k$-th element satisfies the following equation,\n",
    "$$\n",
    "\\phi_k(\\mathbf{x}, y_t, y_{t-1}) = \\begin{cases}\n",
    "1 \\quad \\text{Ether $y_t$ or $y_{t-1}$ is the $k$-th tag of the unique tag list}\\\\\n",
    "0 \\quad \\text{Otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "where $y_t$ and $y_{t-1}$ are the corresponding tag of $x_t$ and $x_{t-1}$ respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Sorry I couldn't implement the algorithm in time! I'll inform you after I make it.__"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  },
  "nav_menu": {},
  "toc": {
   "nav_menu": {
    "height": "68px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
