{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://gist.github.com/2e8eb8bb6f86c614458a9adaa675ad93\n"
     ]
    }
   ],
   "source": [
    "# Don't care. It's just a command for gist update.\n",
    "run(`gist -u https://gist.github.com/2e8eb8bb6f86c614458a9adaa675ad93 slides.ipynb`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "$$\n",
    "\\newcommand{\\argmax}{\\mathop{\\rm arg~max}\\limits}\n",
    "\\newcommand{\\argmin}{\\mathop{\\rm arg~min}\\limits}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chapter5. 系列ラベリング\n",
    "啓太\n",
    "\n",
    "You can access this notebook in [here](http://nbviewer.jupyter.org/gist/KeitaW/2e8eb8bb6f86c614458a9adaa675ad93)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Glossary\n",
    "* 系列(Sequence): Nurture passes nature.\n",
    "* Token: Narture, passes, nature\n",
    "* 品詞(tag): 名詞(Noun), 動詞(Verb), ...\n",
    "* __系列ラベリング__(__Sequence Labeling__): Assign appropriate labels to given sequences. <- Objective!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What we will learn...\n",
    "* HMM(Hidden Markov Model): Supervised \n",
    "    - How to estimate parameters of the model.\n",
    "    - How to assign labels to a sequence with the trained model (Viterbi algorithm).\n",
    "* CRF(Conditional Random Field): Supervised\n",
    "    - How to estimate parameters of the model. (Forward-backward algorithm)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using Iterators.Iterators in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "using PyCall\n",
    "using DataFrames\n",
    "using ScikitLearn\n",
    "using Base.Test\n",
    "using Base.Iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_tagged_dataset (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pyimport nltk.corpus as corpus\n",
    "function load_tagged_dataset(;ndata=Int(1e+06))\n",
    "    tagged_words = corpus.brown[:tagged_words]()\n",
    "    sentences = []; tags_list = []\n",
    "    words = []; tags = []\n",
    "    for (word, tag) in tagged_words\n",
    "        if word == \".\"\n",
    "            # Separate sentence by \".\"\n",
    "            push!(sentences, words); push!(tags_list, tags)\n",
    "            words = []; tags = []\n",
    "        else\n",
    "            push!(words, lowercase.(word)); push!(tags, tag)\n",
    "        end\n",
    "    end\n",
    "    return DataFrame(\n",
    "        sentences = sentences,\n",
    "        tags_list = tags_list)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>sentences</th><th>tags_list</th></tr></thead><tbody><tr><th>1</th><td>Any[\"the\", \"fulton\", \"county\", \"grand\", \"jury\", \"said\", \"friday\", \"an\", \"investigation\", \"of\", \"atlanta's\", \"recent\", \"primary\", \"election\", \"produced\", \"``\", \"no\", \"evidence\", \"''\", \"that\", \"any\", \"irregularities\", \"took\", \"place\"]</td><td>Any[\"AT\", \"NP-TL\", \"NN-TL\", \"JJ-TL\", \"NN-TL\", \"VBD\", \"NR\", \"AT\", \"NN\", \"IN\", \"NP\\$\", \"JJ\", \"NN\", \"NN\", \"VBD\", \"``\", \"AT\", \"NN\", \"''\", \"CS\", \"DTI\", \"NNS\", \"VBD\", \"NN\"]</td></tr><tr><th>2</th><td>Any[\"the\", \"jury\", \"further\", \"said\", \"in\", \"term-end\", \"presentments\", \"that\", \"the\", \"city\", \"executive\", \"committee\", \",\", \"which\", \"had\", \"over-all\", \"charge\", \"of\", \"the\", \"election\", \",\", \"``\", \"deserves\", \"the\", \"praise\", \"and\", \"thanks\", \"of\", \"the\", \"city\", \"of\", \"atlanta\", \"''\", \"for\", \"the\", \"manner\", \"in\", \"which\", \"the\", \"election\", \"was\", \"conducted\"]</td><td>Any[\"AT\", \"NN\", \"RBR\", \"VBD\", \"IN\", \"NN\", \"NNS\", \"CS\", \"AT\", \"NN-TL\", \"JJ-TL\", \"NN-TL\", \",\", \"WDT\", \"HVD\", \"JJ\", \"NN\", \"IN\", \"AT\", \"NN\", \",\", \"``\", \"VBZ\", \"AT\", \"NN\", \"CC\", \"NNS\", \"IN\", \"AT\", \"NN-TL\", \"IN-TL\", \"NP-TL\", \"''\", \"IN\", \"AT\", \"NN\", \"IN\", \"WDT\", \"AT\", \"NN\", \"BEDZ\", \"VBN\"]</td></tr><tr><th>3</th><td>Any[\"the\", \"september-october\", \"term\", \"jury\", \"had\", \"been\", \"charged\", \"by\", \"fulton\", \"superior\", \"court\", \"judge\", \"durwood\", \"pye\", \"to\", \"investigate\", \"reports\", \"of\", \"possible\", \"``\", \"irregularities\", \"''\", \"in\", \"the\", \"hard-fought\", \"primary\", \"which\", \"was\", \"won\", \"by\", \"mayor-nominate\", \"ivan\", \"allen\", \"jr.\"]</td><td>Any[\"AT\", \"NP\", \"NN\", \"NN\", \"HVD\", \"BEN\", \"VBN\", \"IN\", \"NP-TL\", \"JJ-TL\", \"NN-TL\", \"NN-TL\", \"NP\", \"NP\", \"TO\", \"VB\", \"NNS\", \"IN\", \"JJ\", \"``\", \"NNS\", \"''\", \"IN\", \"AT\", \"JJ\", \"NN\", \"WDT\", \"BEDZ\", \"VBN\", \"IN\", \"NN-TL\", \"NP\", \"NP\", \"NP\"]</td></tr><tr><th>4</th><td>Any[\"``\", \"only\", \"a\", \"relative\", \"handful\", \"of\", \"such\", \"reports\", \"was\", \"received\", \"''\", \",\", \"the\", \"jury\", \"said\", \",\", \"``\", \"considering\", \"the\", \"widespread\", \"interest\", \"in\", \"the\", \"election\", \",\", \"the\", \"number\", \"of\", \"voters\", \"and\", \"the\", \"size\", \"of\", \"this\", \"city\", \"''\"]</td><td>Any[\"``\", \"RB\", \"AT\", \"JJ\", \"NN\", \"IN\", \"JJ\", \"NNS\", \"BEDZ\", \"VBN\", \"''\", \",\", \"AT\", \"NN\", \"VBD\", \",\", \"``\", \"IN\", \"AT\", \"JJ\", \"NN\", \"IN\", \"AT\", \"NN\", \",\", \"AT\", \"NN\", \"IN\", \"NNS\", \"CC\", \"AT\", \"NN\", \"IN\", \"DT\", \"NN\", \"''\"]</td></tr><tr><th>5</th><td>Any[\"the\", \"jury\", \"said\", \"it\", \"did\", \"find\", \"that\", \"many\", \"of\", \"georgia's\", \"registration\", \"and\", \"election\", \"laws\", \"``\", \"are\", \"outmoded\", \"or\", \"inadequate\", \"and\", \"often\", \"ambiguous\", \"''\"]</td><td>Any[\"AT\", \"NN\", \"VBD\", \"PPS\", \"DOD\", \"VB\", \"CS\", \"AP\", \"IN\", \"NP\\$\", \"NN\", \"CC\", \"NN\", \"NNS\", \"``\", \"BER\", \"JJ\", \"CC\", \"JJ\", \"CC\", \"RB\", \"JJ\", \"''\"]</td></tr><tr><th>6</th><td>Any[\"it\", \"recommended\", \"that\", \"fulton\", \"legislators\", \"act\", \"``\", \"to\", \"have\", \"these\", \"laws\", \"studied\", \"and\", \"revised\", \"to\", \"the\", \"end\", \"of\", \"modernizing\", \"and\", \"improving\", \"them\", \"''\"]</td><td>Any[\"PPS\", \"VBD\", \"CS\", \"NP\", \"NNS\", \"VB\", \"``\", \"TO\", \"HV\", \"DTS\", \"NNS\", \"VBN\", \"CC\", \"VBN\", \"IN\", \"AT\", \"NN\", \"IN\", \"VBG\", \"CC\", \"VBG\", \"PPO\", \"''\"]</td></tr></tbody></table>"
      ],
      "text/plain": [
       "6×2 DataFrames.DataFrame\n",
       "│ Row │ ├─────┼\n",
       "│ 1   │ │ 2   │ │ 3   │ │ 4   │ │ 5   │ │ 6   │ \n",
       "\n",
       "│ Row │ sentences                                                                                                                                                                                                                                                                                                                                                                       │\n",
       "├─────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ 1   │ Any[\"the\", \"fulton\", \"county\", \"grand\", \"jury\", \"said\", \"friday\", \"an\", \"investigation\", \"of\"  …  \"produced\", \"``\", \"no\", \"evidence\", \"''\", \"that\", \"any\", \"irregularities\", \"took\", \"place\"]                                                                                                                                        │\n",
       "│ 2   │ Any[\"the\", \"jury\", \"further\", \"said\", \"in\", \"term-end\", \"presentments\", \"that\", \"the\", \"city\"  …  \"''\", \"for\", \"the\", \"manner\", \"in\", \"which\", \"the\", \"election\", \"was\", \"conducted\"] │\n",
       "│ 3   │ Any[\"the\", \"september-october\", \"term\", \"jury\", \"had\", \"been\", \"charged\", \"by\", \"fulton\", \"superior\"  …  \"hard-fought\", \"primary\", \"which\", \"was\", \"won\", \"by\", \"mayor-nominate\", \"ivan\", \"allen\", \"jr.\"]                                         │\n",
       "│ 4   │ Any[\"``\", \"only\", \"a\", \"relative\", \"handful\", \"of\", \"such\", \"reports\", \"was\", \"received\"  …  \"number\", \"of\", \"voters\", \"and\", \"the\", \"size\", \"of\", \"this\", \"city\", \"''\"]                                                                         │\n",
       "│ 5   │ Any[\"the\", \"jury\", \"said\", \"it\", \"did\", \"find\", \"that\", \"many\", \"of\", \"georgia's\"  …  \"laws\", \"``\", \"are\", \"outmoded\", \"or\", \"inadequate\", \"and\", \"often\", \"ambiguous\", \"''\"]                                                                                                                                                                   │\n",
       "│ 6   │ Any[\"it\", \"recommended\", \"that\", \"fulton\", \"legislators\", \"act\", \"``\", \"to\", \"have\", \"these\"  …  \"revised\", \"to\", \"the\", \"end\", \"of\", \"modernizing\", \"and\", \"improving\", \"them\", \"''\"]                                                                                                                                                                   │\n",
       "\n",
       "│ Row │ tags_list                                                                                                                                                                                                                                                                                  │\n",
       "├─────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ 1   │ Any[\"AT\", \"NP-TL\", \"NN-TL\", \"JJ-TL\", \"NN-TL\", \"VBD\", \"NR\", \"AT\", \"NN\", \"IN\"  …  \"VBD\", \"``\", \"AT\", \"NN\", \"''\", \"CS\", \"DTI\", \"NNS\", \"VBD\", \"NN\"]                                                                                                                     │\n",
       "│ 2   │ Any[\"AT\", \"NN\", \"RBR\", \"VBD\", \"IN\", \"NN\", \"NNS\", \"CS\", \"AT\", \"NN-TL\"  …  \"''\", \"IN\", \"AT\", \"NN\", \"IN\", \"WDT\", \"AT\", \"NN\", \"BEDZ\", \"VBN\"] │\n",
       "│ 3   │ Any[\"AT\", \"NP\", \"NN\", \"NN\", \"HVD\", \"BEN\", \"VBN\", \"IN\", \"NP-TL\", \"JJ-TL\"  …  \"JJ\", \"NN\", \"WDT\", \"BEDZ\", \"VBN\", \"IN\", \"NN-TL\", \"NP\", \"NP\", \"NP\"]                                                    │\n",
       "│ 4   │ Any[\"``\", \"RB\", \"AT\", \"JJ\", \"NN\", \"IN\", \"JJ\", \"NNS\", \"BEDZ\", \"VBN\"  …  \"NN\", \"IN\", \"NNS\", \"CC\", \"AT\", \"NN\", \"IN\", \"DT\", \"NN\", \"''\"]                                                             │\n",
       "│ 5   │ Any[\"AT\", \"NN\", \"VBD\", \"PPS\", \"DOD\", \"VB\", \"CS\", \"AP\", \"IN\", \"NP\\$\"  …  \"NNS\", \"``\", \"BER\", \"JJ\", \"CC\", \"JJ\", \"CC\", \"RB\", \"JJ\", \"''\"]                                                                                                                                       │\n",
       "│ 6   │ Any[\"PPS\", \"VBD\", \"CS\", \"NP\", \"NNS\", \"VB\", \"``\", \"TO\", \"HV\", \"DTS\"  …  \"VBN\", \"IN\", \"AT\", \"NN\", \"IN\", \"VBG\", \"CC\", \"VBG\", \"PPO\", \"''\"]                                                                                                                                    │"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_words = load_tagged_dataset()\n",
    "head(tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Following command lists all tags(品詞) and words in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{String,1}:\n",
       " \"AT\"   \n",
       " \"NP-TL\"\n",
       " \"NN-TL\"\n",
       " \"JJ-TL\"\n",
       " \"VBD\"  \n",
       " \"NR\"   \n",
       " \"NN\"   \n",
       " \"IN\"   \n",
       " \"NP\\$\" \n",
       " \"JJ\"   "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_tags = unique(flatten(tagged_words[:tags_list]))\n",
    "uniq_tags[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{String,1}:\n",
       " \"the\"          \n",
       " \"fulton\"       \n",
       " \"county\"       \n",
       " \"grand\"        \n",
       " \"jury\"         \n",
       " \"said\"         \n",
       " \"friday\"       \n",
       " \"an\"           \n",
       " \"investigation\"\n",
       " \"of\"           "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_words = unique(flatten(tagged_words[:sentences]))\n",
    "uniq_words[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see meaning of each tag..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n",
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: both ScikitLearn and DataFrames export \"fit!\"; uses of it in module Main must be qualified\n",
      "WARNING: both ScikitLearn and DataFrames export \"predict\"; uses of it in module Main must be qualified\n",
      "WARNING: both ScikitLearn and DataFrames export \"sample\"; uses of it in module Main must be qualified\n"
     ]
    }
   ],
   "source": [
    "@pyimport nltk.help as nlhelp\n",
    "nlhelp.upenn_tagset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "^^;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{String,1}:\n",
       " \"nothing\"  \n",
       " \"has\"      \n",
       " \"been\"     \n",
       " \"done\"     \n",
       " \"yet\"      \n",
       " \"to\"       \n",
       " \"take\"     \n",
       " \"advantage\"\n",
       " \"of\"       \n",
       " \"the\"      "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numdata = Int(1e+03)\n",
    "tagged_words = tagged_words[1:numdata, :]\n",
    "X_train, X_test, y_train, y_test = ScikitLearn.CrossValidation.train_test_split(tagged_words[:sentences], tagged_words[:tags_list], test_size = 0.3);\n",
    "X_train_, X_test_, y_train_, y_test_ =  collect(flatten(X_train)), collect(flatten(X_test)), collect(flatten(y_train)), collect(flatten(y_test));\n",
    "X_train_[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Notation\n",
    "* $\\mathbf{x}$: Data (In this context, it's words).  \n",
    "* $\\mathbf{y}$: Label (In this context, it's tags)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Assumption\n",
    "![](http://iacs-courses.seas.harvard.edu/courses/am207/blog/hmm.png)\n",
    "http://iacs-courses.seas.harvard.edu/courses/am207/blog/lecture-18.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We may rewrite conditional probability of $\\mathbf{x}$ and $\\mathbf{y}$ as follows:\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "P(\\mathbf{x}, \\mathbf{y}) &=&  P(x_{1:T}, y_{1:T}) \\\\\n",
    "    &=& P(x_T|x_{1:T-1}, y_{1:T})P(x_{1:T-1}, y_{1:T}) \\\\\n",
    "    &=& P(x_T|x_{1:T-1}, y_{1:T})P(y_T | x_{1:T-1}, y_{1:{T-1}})P(x_{1:T-1}, y_{1:T-1}) \\\\\n",
    "    &=& \\dots \\\\\n",
    "    &=& \\prod_{i=1}^T  P(x_i|x_{1:i-1}, y_{1:i})P(y_i | x_{1:i-1}, y_{1:i-1}) \\quad \\text{Use the assumption}\\\\\n",
    "    &=& \\prod_{i=1}^T P(x_i|y_i)P(y_i|y_{i-1})\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "Where $T$ is the number of tokens in $\\mathbf{x}$. Note: $P(x_1, y_1) = P(x_1, y_1 | x_0, y_0),  P(y_1) = P(y_1|y_0), P(x_1) = P(x_1|x_0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parameter estimation of the HMM\n",
    "Let $D = \\{ (\\mathbf{x}^{(1)}, \\mathbf{y}^{(1)}), (\\mathbf{x}^{(2)}, \\mathbf{y}^{(2)}), \\dots, (\\mathbf{x}^{(T)}, \\mathbf{y}^{(T)})\\}$ be training dataset. We may define log-likelihood:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\log P(D) &=& \\sum_{(\\mathbf{x}^{(i)}, \\mathbf{y}^{(i)}) \\in D} \\log P(\\mathbf{x}^{(i)}, \\mathbf{y}^{(i)}) \\\\\n",
    "    &=&\\sum_{(\\mathbf{x}^{(i)}, \\mathbf{y}^{(i)}) \\in D} \\log \\prod_{j=1}^T P(x^{(i)}_j|y^{(i)}_j)P(y^{(i)}_j|y^{(i)}_{j-1}) \\\\\n",
    "    &=& \\sum_{(\\mathbf{x}^{(i)}, \\mathbf{y}^{(i)}) \\in D} \\left( \\sum_{j=1}^T \\log P(x^{(i)}_j|y^{(i)}_j) + \\sum_{j=1}^T  \\log P(y^{(i)}_j|y^{(i)}_{j-1}) \\right) \\\\\n",
    "    &=& \\sum_{x, y} n((x, y), D) \\log p_{x|y} + \\sum_{y, y'} n((y', y), D) \\log q_{y|y'}\n",
    "\\end{align}\n",
    "$$\n",
    "where $n((x, y), D)$ be number of word $x$ that have tag $y$, $n((y', y), D)$ be number of tag $y$ that follows $y'$, $p_{x|y}=P(x|y)$ and $q_{y|y'}=P(y|y')$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We want to find $p_{x|y}, q_{y|y'}$ such that\n",
    "$$\n",
    "\\argmax_{p_{x|y}, q_{y|y'}} \\sum_{x, y} n((x, y), D) \\log p_{x|y} + \\sum_{y, y'} n((y', y), D) \\log q_{y|y'}\n",
    "$$\n",
    "subject to $\\sum_{x}p_{x|y} = 1$ and $\\sum_{y}q_{y|y'} = 1$. \n",
    "We may use the method of Lagrange multipliers,\n",
    "$$\n",
    "\\mathscr{L}(p_{x|y}, q_{y|y'}, \\alpha_1, \\alpha_2) = \\sum_{x, y} n((x, y), D) \\log p_{x|y} + \\sum_{y, y'} n((y', y), D) \\log q_{y|y'} + \\alpha_1 (1-\\sum_x p_{x|y}) + \\alpha_2 (1-\\sum_y q_{y|y'})\n",
    "$$\n",
    "Solving $\\partial \\mathscr{L} / \\partial p_{x|y} = 0,\\ \\partial \\mathscr{L} / \\partial q_{y|y'} = 0,\\ \\partial \\mathscr{L} / \\partial \\alpha_1 = 0 \\text{ and } \\partial \\mathscr{L} / \\partial \\alpha_2 = 0$ yields\n",
    "\n",
    "$$\n",
    "p_{x|y} = \\frac{n((x, y), D)}{\\sum_x n((x, y), D)}, \\quad q_{y|y'} = \\frac{n((y', y), D)}{\\sum_y n((y', y), D)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func = (x) -> x^2\n",
    "func(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::#130) (generic function with 1 method)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nxy_ = (words, tags) -> word -> tag -> sum((words .== word) .& (tags .== tag))\n",
    "# n_{tag1 | tag2} in other words, y = tag1; y' = tag2\n",
    "nyy_ = (words, tags) -> tag1 -> tag2 -> sum((tags .== tag1) .& (circshift(tags, 1) .== tag2))\n",
    "# Note order of argments flipped \n",
    "pxy_ = nxy -> uniq_words -> function (tag)\n",
    "    denominator = reduce(+, 0, map(w -> nxy(w)(tag), uniq_words))\n",
    "    (word) -> nxy(word)(tag) == 0 ? 0 : nxy(word)(tag) / denominator\n",
    "end\n",
    "pyy_ = nyy -> uniq_tags  -> function (tag2)\n",
    "    denominator = reduce(+, 0, map(t -> nyy(t)(tag2), uniq_tags))\n",
    "    (tag1) -> nyy(tag1)(tag2) == 0 ? 0 : nyy(tag1)(tag2) / denominator\n",
    "end\n",
    "pxy  = pxy_(nxy_(X_train, y_train))(uniq_words); pyy = pyy_(nyy_(X_train, y_train))(uniq_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Such code often produces many bugs, write test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m\u001b[32mTest Passed\n",
       "\u001b[39m\u001b[22m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data\n",
    "twords = [\"i\", \"am\", \"ai\", \"i\", \"am\", \"governor\"]; tuniq_words = unique(twords)\n",
    "ttags = [\"AT\", \"BT\", \"AT\", \"DT\", \"BT\", \"AT\"]; tuniq_tags = unique(ttags)\n",
    "@test nxy_(twords, ttags)(\"i\")(\"AT\") == 1\n",
    "@test nxy_(twords, ttags)(\"am\")(\"BT\") == 2\n",
    "@test nyy_(twords, ttags)(\"BT\")(\"AT\") == 1\n",
    "@test nyy_(twords, ttags)(\"AT\")(\"BT\") == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m\u001b[32mTest Passed\n",
       "\u001b[39m\u001b[22m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpxy = pxy_(nxy_(twords, ttags))(tuniq_words); tpyy = pyy_(nyy_(twords, ttags))(tuniq_tags) \n",
    "@test tpxy(\"BT\")(\"am\") == 1\n",
    "@test tpyy(\"BT\")(\"AT\") == 1.0\n",
    "@test tpyy(\"AT\")(\"BT\") == 0.3333333333333333\n",
    "@test tpyy(\"DT\")(\"AT\") == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inference with a trained HMM model\n",
    "We want to acquire optimal estimate of tag assignments $\\mathbf{y}^{\\max}$ such that satisfy,\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{y}^{\\max} &=& \\argmax_\\mathbf{y} \\sum_{j} P(\\mathbf{x}, \\mathbf{y}) = \\argmax_\\mathbf{y} \\sum_{j} \\log P(x_j, y_j | x_{j-1}, y_{j-1}) \\\\\n",
    "    &=& \\argmax_\\mathbf{y} \\sum_{j} \\log P(x_j|y_j) + \\log P(y_j|y_{j-1}) \\\\\n",
    "    &=& \\argmax_\\mathbf{y} \\sum_{j} \\log p_{x_j|y_j} + \\log q_{y_j|y_{j-1}} \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Define $\\mathrm{trans}(x_j, y_j, y_{j-1})$ as follows,\n",
    "$$\n",
    "\\mathrm{trans}(x_j, y_j, y_{j-1}) \\equiv \\log P(x_j, y_j | x_{j-1}, y_{j-1}) = \\log p_{x_j|y_j} + \\log q_{y_j|y_{j-1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the end we get,\n",
    "$$\n",
    "\\mathbf{y}^{\\max} = \\argmax_\\mathbf{y} \\sum_j \\mathrm{trans}(x_j, y_j, y_{j-1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Viterbi Algorithm\n",
    "> The Viterbi Algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states – called the Viterbi path – that results in a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (from Wikipedia).\n",
    "\n",
    "__objective__: find $\\mathbf{y}$ such that satisfy, $\\mathbf{y}^{\\max} = \\argmax_\\mathbf{y} \\sum_j \\mathrm{trans}(x_j, y_j, y_{j-1})$.\n",
    "\n",
    "This algorithm consists of two parts which will be discussed in the following slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\begin{cases}\n",
    "t(j, y_j) = \\max_{y_{j-1}} [\\mathrm{trans}(x_j, y_j, y_{j-1}) + t(j-1, y_{j-1})] \\\\\n",
    "s(j, y_j) = \\argmax_{y_{j-1}} [\\mathrm{trans}(x_j, y_j, y_{j-1}) + t(j-1, y_{j-1})]\n",
    "\\end{cases}\n",
    "\\Leftrightarrow\n",
    "\\begin{cases}\n",
    "s(j, y_j) = \\argmax_{y_{j-1}} [\\mathrm{trans}(x_j, y_j, y_{j-1}) + t(j-1, y_{j-1})] \\\\\n",
    "t(j, y_j) = \\mathrm{trans}(x_j, y_j, s(j, y_j)) + t(j-1, s(j, y_j))\n",
    "\\end{cases}\n",
    "\\end{align} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m\u001b[32mTest Passed\n",
       "\u001b[39m\u001b[22m"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag: a current tag, ptag: a previous tag\n",
    "trans_ = (pxy) -> (pyy) -> (word) -> (tag) -> (ptag) -> log(pxy(tag)(word)) + log(pyy(ptag)(tag))\n",
    "# # equivalent efficient yet bit complex form\n",
    "# trans_ = (pxy) -> (pyy) -> function (tag)\n",
    "#     px_ = pxy(tag)\n",
    "#     function (ptag)\n",
    "#         second = log(pyy(ptag)(tag))\n",
    "#         (word) -> log(px_(word)) + second\n",
    "#     end\n",
    "# end\n",
    "@test trans_(tpxy)(tpyy)(\"i\")(\"AT\")(\"BT\") == -1.0986122886681098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "viterbi_fit (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi_fit(words, tags) = pxy_(nxy_(words, tags))(unique(words)), pyy_(nyy_(words, tags))(unique(tags))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "viterbi_forward (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@inline function viterbi_forward(pxy, pyy, words, uniq_tags)\n",
    "    trans = trans_(pxy)(pyy)\n",
    "    T = zeros(Float64, length(words), length(uniq_tags)); S = zeros(Int64, length(words), length(uniq_tags))\n",
    "    for j in 1:length(uniq_tags) T[1, j] = log(pxy(uniq_tags[j])(words[1])) end\n",
    "    for i in 2:length(words)\n",
    "        for j in 1:length(uniq_tags)\n",
    "            (T[i, j], S[i, j]) = findmax([trans(words[i])(uniq_tags[j])(uniq_tags[k])+T[i-1, k] for k in 1:length(uniq_tags)])\n",
    "        end\n",
    "    end\n",
    "    return S, T\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "viterbi_backword (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@inline function viterbi_backword(T, S, uniq_tags, words)\n",
    "    _, j = findmax(T[end, :])\n",
    "    optimal_tags = []\n",
    "    push!(optimal_tags, uniq_tags[j])\n",
    "    for i in length(words):-1:2\n",
    "        push!(optimal_tags, uniq_tags[S[i, j]])\n",
    "        j = S[i, j]\n",
    "    end\n",
    "    return flipdim(optimal_tags, 1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0 0 … 0 0; 1 1 … 4 1; … ; 1 1 … 4 1; 1 1 … 1 5], [0.0 -Inf … -Inf -Inf; -Inf 0.0 … 0.0 -Inf; … ; -Inf -Inf … 0.0 -Inf; -Inf -Inf … -Inf 0.0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twords = [\"i\", \"am\", \"ai\", \"i\", \"am\", \"governor\"]; tuniq_words = unique(twords)\n",
    "ttags = [\"AT\", \"BT\", \"CT\", \"DT\", \"ET\", \"FT\"]; tuniq_tags = unique(ttags)\n",
    "pxy, pyy = viterbi_fit(twords, ttags)\n",
    "S, T = viterbi_forward(pxy, pyy, twords, unique(ttags))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×6 Array{Float64,2}:\n",
       "    0.0  -Inf    -Inf       0.0  -Inf    -Inf  \n",
       " -Inf       0.0  -Inf    -Inf       0.0  -Inf  \n",
       " -Inf    -Inf       0.0  -Inf    -Inf    -Inf  \n",
       " -Inf    -Inf    -Inf       0.0  -Inf    -Inf  \n",
       " -Inf    -Inf    -Inf    -Inf       0.0  -Inf  \n",
       " -Inf    -Inf    -Inf    -Inf    -Inf       0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×6 Array{Int64,2}:\n",
       " 0  0  0  0  0  0\n",
       " 1  1  1  1  4  1\n",
       " 1  1  2  1  1  1\n",
       " 1  1  1  3  1  1\n",
       " 1  1  1  1  4  1\n",
       " 1  1  1  1  1  5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{Any,1}:\n",
       " \"AT\"\n",
       " \"BT\"\n",
       " \"CT\"\n",
       " \"DT\"\n",
       " \"ET\"\n",
       " \"FT\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_tags = viterbi_backword(T, S, unique(ttags), twords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Try the simplest example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from, til = 1, 250\n",
    "xtrain = X_train_[from:til]; ytrain = y_train_[from:til]\n",
    "pxy, pyy = viterbi_fit(xtrain, ytrain)\n",
    "uniq_tags = unique(ytrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from, til = 1, 10\n",
    "xtest = X_train_[from:til]; ytest = y_train_[from:til];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain = String[\"mills\", \"shot\", \"out\", \"in\", \"front\", \"and\", \"kept\", \"the\", \"lead\", \"through\", \"two\", \"thirds\", \"of\", \"the\", \"race\", \"(\", \"2\", \")\", \"fulton\", \"legislators\", \"``\", \"work\", \"with\", \"city\", \"officials\", \"to\", \"pass\", \"enabling\", \"legislation\", \"that\", \"will\", \"permit\", \"the\", \"establishment\", \"of\", \"a\", \"fair\", \"and\", \"equitable\", \"''\", \"pension\", \"plan\", \"for\", \"city\", \"employes\", \"``\", \"you\", \"take\", \"out\", \"of\", \"circulation\", \"many\", \"millions\", \"of\", \"dollars\", \"''\", \"``\", \"he\", \"is\", \"wrong\", \"to\", \"inject\", \"eisenhower\", \"into\", \"this\", \"campaign\", \"''\", \",\", \"he\", \"said\", \",\", \"``\", \"because\", \"the\", \"primary\", \"is\", \"being\", \"waged\", \"on\", \"state\", \"issues\", \"and\", \"i\", \"will\", \"not\", \"be\", \"forced\", \"into\", \"re-arguing\", \"an\", \"old\", \"national\", \"campaign\", \"''\", \"austin\", \",\", \"texas\", \"--\", \"state\", \"representatives\", \"decided\", \"thursday\", \"against\", \"taking\", \"a\", \"poll\", \"on\", \"what\", \"kind\", \"of\", \"taxes\", \"texans\", \"would\", \"prefer\", \"to\", \"pay\", \"trenton\", \"--\", \"fifteen\", \"members\", \"of\", \"the\", \"republican\", \"state\", \"committee\", \"who\", \"are\", \"retiring\", \"--\", \"voluntarily\", \"--\", \"this\", \"year\", \"were\", \"honored\", \"yesterday\", \"by\", \"their\", \"colleagues\", \"this\", \"is\", \"largely\", \"because\", \"of\", \"the\", \"unpredictability\", \"of\", \"the\", \"man\", \"who\", \"operates\", \"the\", \"helm\", \"of\", \"the\", \"state\", \"government\", \"and\", \"is\", \"the\", \"elected\", \"leader\", \"of\", \"its\", \"two\", \"million\", \"inhabitants\", \"--\", \"gov.\", \"ross\", \"barnett\", \"he\", \"said\", \"that\", \"the\", \"group\", \"has\", \"no\", \"candidates\", \"for\", \"the\", \"charter\", \"commission\", \"in\", \"mind\", \"at\", \"present\", \",\", \"but\", \"that\", \"it\", \"will\", \"undoubtedly\", \"endorse\", \"candidates\", \"when\", \"the\", \"time\", \"comes\", \"if\", \"the\", \"orioles\", \"are\", \"to\", \"break\", \"their\", \"losing\", \"streak\", \"within\", \"the\", \"next\", \"two\", \"days\", \",\", \"it\", \"will\", \"have\", \"to\", \"be\", \"at\", \"the\", \"expense\", \"of\", \"the\", \"american\", \"league\", \"champion\", \"new\", \"york\", \"yankees\", \",\", \"who\", \"come\", \"in\", \"here\", \"tomorrow\", \"for\", \"a\", \"night\", \"game\", \"and\", \"a\", \"single\", \"test\", \"sunday\", \"afternoon\", \"underlying\", \"concern\", \"passage\", \"of\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0 0 … 0 0; 1 1 … 1 1; … ; 1 1 … 1 1; 1 1 … 1 1], [-1.79176 -Inf … -Inf -Inf; -Inf -5.19296 … -Inf -Inf; … ; -Inf -Inf … -Inf -Inf; -Inf -Inf … -Inf -Inf])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show xtrain;\n",
    "S, T = viterbi_forward(pxy, pyy, xtest, uniq_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "S, T = viterbi_forward(pxy, pyy,xtest, uniq_tags);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_tags = Any[\"NP\", \"VBD\", \"RP\", \"IN\", \"NN\", \"CC\", \"VBD\", \"AT\", \"NN\", \"IN\"]\n",
      "ytest = String[\"NP\", \"VBD\", \"RP\", \"IN\", \"NN\", \"CC\", \"VBD\", \"AT\", \"NN\", \"IN\"]\n"
     ]
    }
   ],
   "source": [
    "optimal_tags = viterbi_backword(T, S, uniq_tags, xtest)\n",
    "@show optimal_tags;\n",
    "@show ytest;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So far, so good. Try another example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtest = String[\"nothing\", \"has\", \"been\", \"done\", \"yet\", \"to\", \"take\", \"advantage\", \"of\", \"the\"]\n",
      "xtest2 = String[\"???\", \"has\", \"been\", \"done\", \"yet\", \"to\", \"take\", \"advantage\", \"of\", \"the\"]\n"
     ]
    }
   ],
   "source": [
    "@show xtest\n",
    "xtest2 = xtest; xtest2[1] = \"???\"\n",
    "@show xtest2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_tags = Any[\"PN\", \"PN\", \"PN\", \"PN\", \"PN\", \"PN\", \"PN\", \"PN\", \"PN\", \"PN\"]\n",
      "ytest = String[\"PN\", \"HVZ\", \"BEN\", \"VBN\", \"RB\", \"TO\", \"VB\", \"NN\", \"IN\", \"AT\"]\n"
     ]
    }
   ],
   "source": [
    "S, T = viterbi_forward(pxy, pyy, xtest2, uniq_tags)\n",
    "optimal_tags = viterbi_backword(T, S, uniq_tags, xtest2)\n",
    "@show optimal_tags;\n",
    "@show ytest;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×53 Array{Float64,2}:\n",
       " -Inf  -Inf  -Inf  -Inf  -Inf  -Inf  …  -Inf  -Inf  -Inf  -Inf  -Inf  -Inf\n",
       " -Inf  -Inf  -Inf  -Inf  -Inf  -Inf     -Inf  -Inf  -Inf  -Inf  -Inf  -Inf\n",
       " -Inf  -Inf  -Inf  -Inf  -Inf  -Inf     -Inf  -Inf  -Inf  -Inf  -Inf  -Inf\n",
       " -Inf  -Inf  -Inf  -Inf  -Inf  -Inf     -Inf  -Inf  -Inf  -Inf  -Inf  -Inf\n",
       " -Inf  -Inf  -Inf  -Inf  -Inf  -Inf     -Inf  -Inf  -Inf  -Inf  -Inf  -Inf\n",
       " -Inf  -Inf  -Inf  -Inf  -Inf  -Inf  …  -Inf  -Inf  -Inf  -Inf  -Inf  -Inf\n",
       " -Inf  -Inf  -Inf  -Inf  -Inf  -Inf     -Inf  -Inf  -Inf  -Inf  -Inf  -Inf\n",
       " -Inf  -Inf  -Inf  -Inf  -Inf  -Inf     -Inf  -Inf  -Inf  -Inf  -Inf  -Inf\n",
       " -Inf  -Inf  -Inf  -Inf  -Inf  -Inf     -Inf  -Inf  -Inf  -Inf  -Inf  -Inf\n",
       " -Inf  -Inf  -Inf  -Inf  -Inf  -Inf     -Inf  -Inf  -Inf  -Inf  -Inf  -Inf"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"http://i0.kym-cdn.com/entries/icons/original/000/002/252/NoMeGusta.jpg\" alt=\"\" width=\"500px\" height=\"500px\">\n",
    "http://i0.kym-cdn.com/entries/icons/original/000/002/252/NoMeGusta.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We may use possible (messy) workaround which is shown below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::#58) (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nxy__ = (words, tags) -> word -> tag -> sum((words .== word) .& (tags .== tag)) + 1\n",
    "# n_{tag1 | tag2} in other words, y = tag1; y' = tag2\n",
    "nyy__ = (words, tags) -> tag1 -> tag2 -> sum((tags .== tag1) .& (circshift(tags, 1) .== tag2)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "viterbi_fit_alt (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi_fit_alt(words, tags) = pxy_(nxy__(words, tags))(unique(words)), pyy_(nyy__(words, tags))(unique(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_tags = Any[\"JJ\", \"NN\", \"IN\", \"AT\", \"NN\", \"IN\", \"AT\", \"NN\", \"IN\", \"AT\"]\n",
      "ytest = String[\"PN\", \"HVZ\", \"BEN\", \"VBN\", \"RB\", \"TO\", \"VB\", \"NN\", \"IN\", \"AT\"]\n"
     ]
    }
   ],
   "source": [
    "pxy, pyy = viterbi_fit_alt(xtrain, ytrain);\n",
    "S, T = viterbi_forward(pxy, pyy, xtest2, uniq_tags)\n",
    "optimal_tags = viterbi_backword(T, S, uniq_tags, xtest2)\n",
    "@show optimal_tags;\n",
    "@show ytest;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×53 Array{Float64,2}:\n",
       "  -5.09375   -5.09987   -5.09375  …   -5.09987   -5.09375   -5.09375\n",
       " -13.5078   -12.3908   -13.5078      -13.6534   -14.0596   -13.9517 \n",
       " -21.4919   -21.199    -20.1056      -20.909    -21.1745   -20.9926 \n",
       " -28.8599   -28.5555   -28.8599      -28.8349   -28.7057   -28.1667 \n",
       " -35.9748   -35.9119   -35.9748      -35.9809   -35.8207   -35.2817 \n",
       " -43.3411   -43.2684   -43.3411   …  -43.3472   -42.9948   -42.8128 \n",
       " -48.7294   -48.7356   -48.7294      -48.7356   -48.7294   -48.7294 \n",
       " -55.7156   -55.7217   -55.7156      -55.7217   -55.7156   -55.0224 \n",
       " -62.7355   -62.7416   -62.7355      -62.7416   -62.0424   -62.7355 \n",
       " -67.9106   -67.9167   -67.9106      -67.9167   -67.9106   -67.9106 "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_tags = Any[\"IN\", \"AT\", \"NN\", \"IN\", \"AT\", \"NN\", \"IN\", \"AT\", \"NN\", \"IN\", \"AT\"]\n",
      "testlabel = String[\"VBG\", \"IN\", \"PP\\$\", \"NN\", \"AT\", \"JJ\", \"NN\", \"MD\", \"VB\", \"DTI\", \"NN\"]\n"
     ]
    }
   ],
   "source": [
    "testdata = [\"contributing\", \"to\", \"its\", \"defeat\", \"the\", \"new\", \"year\", \"might\", \"see\", \"some\", \"house-cleaning\"]\n",
    "testlabel = [\"VBG\", \"IN\", \"PP\\$\", \"NN\", \"AT\", \"JJ\", \"NN\", \"MD\", \"VB\", \"DTI\", \"NN\"]\n",
    "S, T = viterbi_forward(pxy, pyy, testdata, uniq_tags)\n",
    "optimal_tags = viterbi_backword(T, S, uniq_tags, testdata)\n",
    "@show optimal_tags;\n",
    "@show testlabel;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_tags = Any[\"IN\", \"AT\", \"NN\", \"IN\", \"AT\", \"NN\", \"IN\", \"AT\", \"NN\", \"IN\", \"AT\"]\n",
      "testlabel = String[\"VBG\", \"IN\", \"PP\\$\", \"NN\", \"AT\", \"JJ\", \"NN\", \"MD\", \"VB\", \"DTI\", \"NN\"]\n"
     ]
    }
   ],
   "source": [
    "testdata = [\"???\", \"to\", \"its\", \"defeat\", \"the\", \"new\", \"year\", \"might\", \"see\", \"some\", \"house-cleaning\"]\n",
    "testlabel = [\"VBG\", \"IN\", \"PP\\$\", \"NN\", \"AT\", \"JJ\", \"NN\", \"MD\", \"VB\", \"DTI\", \"NN\"]\n",
    "S, T = viterbi_forward(pxy, pyy, testdata, uniq_tags)\n",
    "optimal_tags = viterbi_backword(T, S, uniq_tags, testdata)\n",
    "@show optimal_tags;\n",
    "@show testlabel;"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  },
  "nav_menu": {},
  "toc": {
   "nav_menu": {
    "height": "198px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
