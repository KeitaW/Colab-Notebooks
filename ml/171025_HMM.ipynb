{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://gist.github.com/2e8eb8bb6f86c614458a9adaa675ad93\n"
     ]
    }
   ],
   "source": [
    "# Don't care. It's just a command for gist update.\n",
    "run(`gist -u https://gist.github.com/2e8eb8bb6f86c614458a9adaa675ad93 HMM.ipynb`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "$$\n",
    "\\newcommand{\\argmax}{\\mathop{\\rm arg~max}\\limits}\n",
    "\\newcommand{\\argmin}{\\mathop{\\rm arg~min}\\limits}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chapter5. 系列ラベリング\n",
    "啓太\n",
    "\n",
    "You can access this notebook in [here](http://nbviewer.jupyter.org/gist/KeitaW/2e8eb8bb6f86c614458a9adaa675ad93)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Glossary\n",
    "* 系列(Sequence): Nurture passes nature.\n",
    "* Token: Narture, passes, nature\n",
    "* 品詞(tag): 名詞(Noun), 動詞(Verb), ...\n",
    "* __系列ラベリング__(__Sequence Labeling__): Assign appropriate labels to given sequences. <- Objective!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What we will learn...\n",
    "* HMM(Hidden Markov Model): Supervised \n",
    "    - How to estimate parameters of the model.\n",
    "    - How to assign labels to a sequence with the trained model (Viterbi algorithm).\n",
    "* CRF(Conditional Random Field): Unsupervised\n",
    "    - How to estimate parameters of the model. (Forward-backward algorithm)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using Iterators.Iterators in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "using PyCall\n",
    "using DataFrames\n",
    "using ScikitLearn\n",
    "using Base.Test\n",
    "using Base.Iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_tagged_dataset (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pyimport nltk.corpus as corpus\n",
    "function load_tagged_dataset(;ndata=Int(1e+06))\n",
    "    tagged_words = corpus.brown[:tagged_words]()\n",
    "    sentences = []; tags_list = []\n",
    "    words = []; tags = []\n",
    "    for (word, tag) in tagged_words\n",
    "        if word == \".\"\n",
    "            # Separate sentence by \".\"\n",
    "            push!(sentences, words); push!(tags_list, tags)\n",
    "            words = []; tags = []\n",
    "        else\n",
    "            push!(words, lowercase.(word)); push!(tags, tag)\n",
    "        end\n",
    "    end\n",
    "    return DataFrame(\n",
    "        sentences = sentences,\n",
    "        tags_list = tags_list)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>sentences</th><th>tags_list</th></tr></thead><tbody><tr><th>1</th><td>Any[\"the\", \"fulton\", \"county\", \"grand\", \"jury\", \"said\", \"friday\", \"an\", \"investigation\", \"of\", \"atlanta's\", \"recent\", \"primary\", \"election\", \"produced\", \"``\", \"no\", \"evidence\", \"''\", \"that\", \"any\", \"irregularities\", \"took\", \"place\"]</td><td>Any[\"AT\", \"NP-TL\", \"NN-TL\", \"JJ-TL\", \"NN-TL\", \"VBD\", \"NR\", \"AT\", \"NN\", \"IN\", \"NP\\$\", \"JJ\", \"NN\", \"NN\", \"VBD\", \"``\", \"AT\", \"NN\", \"''\", \"CS\", \"DTI\", \"NNS\", \"VBD\", \"NN\"]</td></tr><tr><th>2</th><td>Any[\"the\", \"jury\", \"further\", \"said\", \"in\", \"term-end\", \"presentments\", \"that\", \"the\", \"city\", \"executive\", \"committee\", \",\", \"which\", \"had\", \"over-all\", \"charge\", \"of\", \"the\", \"election\", \",\", \"``\", \"deserves\", \"the\", \"praise\", \"and\", \"thanks\", \"of\", \"the\", \"city\", \"of\", \"atlanta\", \"''\", \"for\", \"the\", \"manner\", \"in\", \"which\", \"the\", \"election\", \"was\", \"conducted\"]</td><td>Any[\"AT\", \"NN\", \"RBR\", \"VBD\", \"IN\", \"NN\", \"NNS\", \"CS\", \"AT\", \"NN-TL\", \"JJ-TL\", \"NN-TL\", \",\", \"WDT\", \"HVD\", \"JJ\", \"NN\", \"IN\", \"AT\", \"NN\", \",\", \"``\", \"VBZ\", \"AT\", \"NN\", \"CC\", \"NNS\", \"IN\", \"AT\", \"NN-TL\", \"IN-TL\", \"NP-TL\", \"''\", \"IN\", \"AT\", \"NN\", \"IN\", \"WDT\", \"AT\", \"NN\", \"BEDZ\", \"VBN\"]</td></tr><tr><th>3</th><td>Any[\"the\", \"september-october\", \"term\", \"jury\", \"had\", \"been\", \"charged\", \"by\", \"fulton\", \"superior\", \"court\", \"judge\", \"durwood\", \"pye\", \"to\", \"investigate\", \"reports\", \"of\", \"possible\", \"``\", \"irregularities\", \"''\", \"in\", \"the\", \"hard-fought\", \"primary\", \"which\", \"was\", \"won\", \"by\", \"mayor-nominate\", \"ivan\", \"allen\", \"jr.\"]</td><td>Any[\"AT\", \"NP\", \"NN\", \"NN\", \"HVD\", \"BEN\", \"VBN\", \"IN\", \"NP-TL\", \"JJ-TL\", \"NN-TL\", \"NN-TL\", \"NP\", \"NP\", \"TO\", \"VB\", \"NNS\", \"IN\", \"JJ\", \"``\", \"NNS\", \"''\", \"IN\", \"AT\", \"JJ\", \"NN\", \"WDT\", \"BEDZ\", \"VBN\", \"IN\", \"NN-TL\", \"NP\", \"NP\", \"NP\"]</td></tr><tr><th>4</th><td>Any[\"``\", \"only\", \"a\", \"relative\", \"handful\", \"of\", \"such\", \"reports\", \"was\", \"received\", \"''\", \",\", \"the\", \"jury\", \"said\", \",\", \"``\", \"considering\", \"the\", \"widespread\", \"interest\", \"in\", \"the\", \"election\", \",\", \"the\", \"number\", \"of\", \"voters\", \"and\", \"the\", \"size\", \"of\", \"this\", \"city\", \"''\"]</td><td>Any[\"``\", \"RB\", \"AT\", \"JJ\", \"NN\", \"IN\", \"JJ\", \"NNS\", \"BEDZ\", \"VBN\", \"''\", \",\", \"AT\", \"NN\", \"VBD\", \",\", \"``\", \"IN\", \"AT\", \"JJ\", \"NN\", \"IN\", \"AT\", \"NN\", \",\", \"AT\", \"NN\", \"IN\", \"NNS\", \"CC\", \"AT\", \"NN\", \"IN\", \"DT\", \"NN\", \"''\"]</td></tr><tr><th>5</th><td>Any[\"the\", \"jury\", \"said\", \"it\", \"did\", \"find\", \"that\", \"many\", \"of\", \"georgia's\", \"registration\", \"and\", \"election\", \"laws\", \"``\", \"are\", \"outmoded\", \"or\", \"inadequate\", \"and\", \"often\", \"ambiguous\", \"''\"]</td><td>Any[\"AT\", \"NN\", \"VBD\", \"PPS\", \"DOD\", \"VB\", \"CS\", \"AP\", \"IN\", \"NP\\$\", \"NN\", \"CC\", \"NN\", \"NNS\", \"``\", \"BER\", \"JJ\", \"CC\", \"JJ\", \"CC\", \"RB\", \"JJ\", \"''\"]</td></tr><tr><th>6</th><td>Any[\"it\", \"recommended\", \"that\", \"fulton\", \"legislators\", \"act\", \"``\", \"to\", \"have\", \"these\", \"laws\", \"studied\", \"and\", \"revised\", \"to\", \"the\", \"end\", \"of\", \"modernizing\", \"and\", \"improving\", \"them\", \"''\"]</td><td>Any[\"PPS\", \"VBD\", \"CS\", \"NP\", \"NNS\", \"VB\", \"``\", \"TO\", \"HV\", \"DTS\", \"NNS\", \"VBN\", \"CC\", \"VBN\", \"IN\", \"AT\", \"NN\", \"IN\", \"VBG\", \"CC\", \"VBG\", \"PPO\", \"''\"]</td></tr></tbody></table>"
      ],
      "text/plain": [
       "6×2 DataFrames.DataFrame\n",
       "│ Row │ ├─────┼\n",
       "│ 1   │ │ 2   │ │ 3   │ │ 4   │ │ 5   │ │ 6   │ \n",
       "\n",
       "│ Row │ sentences                                                                                                                                                                                                                                                                                                                                                                       │\n",
       "├─────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ 1   │ Any[\"the\", \"fulton\", \"county\", \"grand\", \"jury\", \"said\", \"friday\", \"an\", \"investigation\", \"of\"  …  \"produced\", \"``\", \"no\", \"evidence\", \"''\", \"that\", \"any\", \"irregularities\", \"took\", \"place\"]                                                                                                                                        │\n",
       "│ 2   │ Any[\"the\", \"jury\", \"further\", \"said\", \"in\", \"term-end\", \"presentments\", \"that\", \"the\", \"city\"  …  \"''\", \"for\", \"the\", \"manner\", \"in\", \"which\", \"the\", \"election\", \"was\", \"conducted\"] │\n",
       "│ 3   │ Any[\"the\", \"september-october\", \"term\", \"jury\", \"had\", \"been\", \"charged\", \"by\", \"fulton\", \"superior\"  …  \"hard-fought\", \"primary\", \"which\", \"was\", \"won\", \"by\", \"mayor-nominate\", \"ivan\", \"allen\", \"jr.\"]                                         │\n",
       "│ 4   │ Any[\"``\", \"only\", \"a\", \"relative\", \"handful\", \"of\", \"such\", \"reports\", \"was\", \"received\"  …  \"number\", \"of\", \"voters\", \"and\", \"the\", \"size\", \"of\", \"this\", \"city\", \"''\"]                                                                         │\n",
       "│ 5   │ Any[\"the\", \"jury\", \"said\", \"it\", \"did\", \"find\", \"that\", \"many\", \"of\", \"georgia's\"  …  \"laws\", \"``\", \"are\", \"outmoded\", \"or\", \"inadequate\", \"and\", \"often\", \"ambiguous\", \"''\"]                                                                                                                                                                   │\n",
       "│ 6   │ Any[\"it\", \"recommended\", \"that\", \"fulton\", \"legislators\", \"act\", \"``\", \"to\", \"have\", \"these\"  …  \"revised\", \"to\", \"the\", \"end\", \"of\", \"modernizing\", \"and\", \"improving\", \"them\", \"''\"]                                                                                                                                                                   │\n",
       "\n",
       "│ Row │ tags_list                                                                                                                                                                                                                                                                                  │\n",
       "├─────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ 1   │ Any[\"AT\", \"NP-TL\", \"NN-TL\", \"JJ-TL\", \"NN-TL\", \"VBD\", \"NR\", \"AT\", \"NN\", \"IN\"  …  \"VBD\", \"``\", \"AT\", \"NN\", \"''\", \"CS\", \"DTI\", \"NNS\", \"VBD\", \"NN\"]                                                                                                                     │\n",
       "│ 2   │ Any[\"AT\", \"NN\", \"RBR\", \"VBD\", \"IN\", \"NN\", \"NNS\", \"CS\", \"AT\", \"NN-TL\"  …  \"''\", \"IN\", \"AT\", \"NN\", \"IN\", \"WDT\", \"AT\", \"NN\", \"BEDZ\", \"VBN\"] │\n",
       "│ 3   │ Any[\"AT\", \"NP\", \"NN\", \"NN\", \"HVD\", \"BEN\", \"VBN\", \"IN\", \"NP-TL\", \"JJ-TL\"  …  \"JJ\", \"NN\", \"WDT\", \"BEDZ\", \"VBN\", \"IN\", \"NN-TL\", \"NP\", \"NP\", \"NP\"]                                                    │\n",
       "│ 4   │ Any[\"``\", \"RB\", \"AT\", \"JJ\", \"NN\", \"IN\", \"JJ\", \"NNS\", \"BEDZ\", \"VBN\"  …  \"NN\", \"IN\", \"NNS\", \"CC\", \"AT\", \"NN\", \"IN\", \"DT\", \"NN\", \"''\"]                                                             │\n",
       "│ 5   │ Any[\"AT\", \"NN\", \"VBD\", \"PPS\", \"DOD\", \"VB\", \"CS\", \"AP\", \"IN\", \"NP\\$\"  …  \"NNS\", \"``\", \"BER\", \"JJ\", \"CC\", \"JJ\", \"CC\", \"RB\", \"JJ\", \"''\"]                                                                                                                                       │\n",
       "│ 6   │ Any[\"PPS\", \"VBD\", \"CS\", \"NP\", \"NNS\", \"VB\", \"``\", \"TO\", \"HV\", \"DTS\"  …  \"VBN\", \"IN\", \"AT\", \"NN\", \"IN\", \"VBG\", \"CC\", \"VBG\", \"PPO\", \"''\"]                                                                                                                                    │"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_words = load_tagged_dataset()\n",
    "head(tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Following command lists all tags(品詞) and words in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{String,1}:\n",
       " \"AT\"   \n",
       " \"NP-TL\"\n",
       " \"NN-TL\"\n",
       " \"JJ-TL\"\n",
       " \"VBD\"  \n",
       " \"NR\"   \n",
       " \"NN\"   \n",
       " \"IN\"   \n",
       " \"NP\\$\" \n",
       " \"JJ\"   "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_tags = unique(flatten(tagged_words[:tags_list]))\n",
    "uniq_tags[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{String,1}:\n",
       " \"the\"          \n",
       " \"fulton\"       \n",
       " \"county\"       \n",
       " \"grand\"        \n",
       " \"jury\"         \n",
       " \"said\"         \n",
       " \"friday\"       \n",
       " \"an\"           \n",
       " \"investigation\"\n",
       " \"of\"           "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_words = unique(flatten(tagged_words[:sentences]))\n",
    "uniq_words[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see meaning of each tag..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "@pyimport nltk.help as nlhelp\n",
    "nlhelp.upenn_tagset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "^^;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "numdata = Int(1e+03)\n",
    "tagged_words = tagged_words[1:numdata, :]\n",
    "X_train, X_test, y_train, y_test = ScikitLearn.CrossValidation.train_test_split(tagged_words[:sentences], tagged_words[:tags_list], test_size = 0.3);\n",
    "X_train_, X_test_, y_train_, y_test_ =  collect(flatten(X_train)), collect(flatten(X_test)), collect(flatten(y_train)), collect(flatten(y_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Notation\n",
    "* $\\mathbf{x}$: Data (In this context, it's words).  \n",
    "* $\\mathbf{y}$: Label (In this context, it's tags)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Assumption\n",
    "![](http://iacs-courses.seas.harvard.edu/courses/am207/blog/hmm.png)\n",
    "http://iacs-courses.seas.harvard.edu/courses/am207/blog/lecture-18.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We may rewrite conditional probability of $\\mathbf{x}$ and $\\mathbf{y}$ as follows:\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "P(\\mathbf{x}, \\mathbf{y}) &=&  P(x_{1:T}, y_{1:T}) \\\\\n",
    "    &=& P(x_T|x_{1:T-1}, y_{1:T})P(x_{1:T-1}, y_{1:T}) \\\\\n",
    "    &=& P(x_T|x_{1:T-1}, y_{1:T})P(y_T | x_{1:T-1}, y_{1:T})P(x_{1:T-1}, y_{1:T-1}) \\\\\n",
    "    &=& \\dots \\\\\n",
    "    &=& \\prod_{i=1}^T  P(x_i|x_{1:i-1}, y_{1:i})P(y_i | x_{1:i-1}, y_{1:i-1}) \\quad \\text{Use the assumption}\\\\\n",
    "    &=& \\prod_{i=1}^T P(x_i|y_i)P(y_i|y_{i-1})\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "Where $T$ is the number of tokens in $\\mathbf{x}$. Note: $P(x_1, y_1) = P(x_1, y_1 | x_0, y_0),  P(y_1) = P(y_1|y_0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parameter estimation of the HMM\n",
    "Let $D = \\{ (\\mathbf{x}^{(1)}, \\mathbf{y}^{(1)}), (\\mathbf{x}^{(2)}, \\mathbf{y}^{(2)}), \\dots, (\\mathbf{x}^{(T)}, \\mathbf{y}^{(T)})\\}$ be training dataset. We may define log-likelihood:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\log P(D) &=& \\sum_{(\\mathbf{x}^{(i)}, \\mathbf{y}^{(i)}) \\in D} \\log P(\\mathbf{x}^{(i)}, \\mathbf{y}^{(i)}) \\\\\n",
    "    &=&\\sum_{(\\mathbf{x}^{(i)}, \\mathbf{y}^{(i)}) \\in D} \\log \\prod_{j=1}^T P(x^{(i)}_j|y^{(i)}_j)P(y^{(i)}_j|y^{(i)}_{j-1}) \\\\\n",
    "    &=& \\sum_{(\\mathbf{x}^{(i)}, \\mathbf{y}^{(i)}) \\in D} \\left( \\sum_{j=1}^T \\log P(x^{(i)}_j|y^{(i)}_j) \\sum_{j=1}^T + \\log P(y^{(i)}_j|y^{(i)}_{j-1}) \\right) \\\\\n",
    "    &=& \\sum_{x, y} n((x, y), D) \\log p_{x|y} + \\sum_{y, y'} n((y', y), D) \\log q_{y|y'}\n",
    "\\end{align}\n",
    "$$\n",
    "where $n((x, y), D)$ be number of word $x$ that have tag $y$, $n((y', y), D)$ be number of tag $y$ that follows $y'$, $p_{x|y}=P(x|y)$ and $q_{y|y'}=P(y|y')$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We want to find $p_{x|y}, q_{y|y'}$ such that\n",
    "$$\n",
    "\\argmax_{p_{x|y}, q_{y|y'}} \\sum_{x, y} n((x, y), D) \\log p_{x|y} + \\sum_{y, y'} n((y', y), D) \\log q_{y|y'}\n",
    "$$\n",
    "subject to $\\sum_{x}p_{x|y} = 1$ and $\\sum_{x}q_{y|y'} = 1$. \n",
    "We may use the method of Lagrange multipliers,\n",
    "$$\n",
    "\\mathscr{L}(p_{x|y}, q_{y|y'}, \\alpha_1, \\alpha_2) = \\sum_{x, y} n((x, y), D) \\log p_{x|y} + \\sum_{y, y'} n((y', y), D) \\log q_{y|y'} + \\alpha_1 (1-\\sum_x p_{x|y}) + \\alpha_2 (1-\\sum_y q_{y|y'})\n",
    "$$\n",
    "Solving $\\partial \\mathscr{L} / \\partial p_{x|y} = 0,\\ \\partial \\mathscr{L} / \\partial q_{y|y'} = 0,\\ \\partial \\mathscr{L} / \\partial \\alpha_1 = 0 \\text{ and } \\partial \\mathscr{L} / \\partial \\alpha_2 = 0$ yields\n",
    "\n",
    "$$\n",
    "p_{x|y} = \\frac{n((x, y), D)}{\\sum_x n((x, y), D)}, \\quad q_{y|y'} = \\frac{n((y', y), D)}{\\sum_y n((y', y), D)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::#66) (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nxy_ = (words, tags) -> word -> tag -> sum((words .== word) .& (tags .== tag))\n",
    "# n_{tag1 | tag2} in other words, y = tag1; y' = tag2\n",
    "nyy_ = (words, tags) -> tag1 -> tag2 -> sum((tags .== tag1) .& (circshift(tags, 1) .== tag2))\n",
    "# Note order of argments flipped \n",
    "pxy_ = nxy -> uniq_words -> function (tag)\n",
    "    denominator = reduce(+, 0, map(w -> nxy(w)(tag), uniq_words))\n",
    "    (word) -> nxy(word)(tag) == 0 ? 0 : nxy(word)(tag) / denominator\n",
    "end\n",
    "pyy_ = nyy -> uniq_tags  -> function (tag2)\n",
    "    denominator = reduce(+, 0, map(t -> nyy(t)(tag2), uniq_tags))\n",
    "    (tag1) -> nyy(tag1)(tag2) == 0 ? 0 : nyy(tag1)(tag2) / denominator\n",
    "end\n",
    "pxy  = pxy_(nxy_(X_train, y_train))(uniq_words); pyy = pyy_(nyy_(X_train, y_train))(uniq_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Such code often produces many bugs, write test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m\u001b[32mTest Passed\n",
       "\u001b[39m\u001b[22m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data\n",
    "twords = [\"i\", \"am\", \"ai\", \"i\", \"am\", \"governor\"]; tuniq_words = unique(twords)\n",
    "ttags = [\"AT\", \"BT\", \"AT\", \"DT\", \"BT\", \"AT\"]; tuniq_tags = unique(ttags)\n",
    "@test nxy_(twords, ttags)(\"i\")(\"AT\") == 1\n",
    "@test nxy_(twords, ttags)(\"am\")(\"BT\") == 2\n",
    "@test nyy_(twords, ttags)(\"BT\")(\"AT\") == 1\n",
    "@test nyy_(twords, ttags)(\"AT\")(\"BT\") == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m\u001b[32mTest Passed\n",
       "\u001b[39m\u001b[22m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpxy = pxy_(nxy_(twords, ttags))(tuniq_words); tpyy = pyy_(nyy_(twords, ttags))(tuniq_tags) \n",
    "@test tpxy(\"BT\")(\"am\") == 1\n",
    "@test tpyy(\"BT\")(\"AT\") == 1.0\n",
    "@test tpyy(\"AT\")(\"BT\") == 0.3333333333333333\n",
    "@test tpyy(\"DT\")(\"AT\") == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inference with a trained HMM model\n",
    "We want to acquire optimal estimate of tag assignments $\\mathbf{y}^{\\max}$ such that satisfy,\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{y}^{\\max} &=& \\argmax_\\mathbf{y} \\sum_{j} P(\\mathbf{x}, \\mathbf{y}) = \\argmax_\\mathbf{y} \\sum_{j} \\log P(x_j, y_j | x_{j-1}, y_{j-1}) \\\\\n",
    "    &=& \\argmax_\\mathbf{y} \\sum_{j} \\log P(x_j|y_j) + \\log P(y_j|y_{j-1}) \\\\\n",
    "    &=& \\argmax_\\mathbf{y} \\sum_{j} \\log p_{x_j|y_j} + \\log q_{y_j|y_{j-1}} \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Define $\\mathrm{trans}(x_j, y_j, y_{j-1})$ as follows,\n",
    "$$\n",
    "\\mathrm{trans}(x_j, y_j, y_{j-1}) \\equiv \\log P(x_j, y_j | x_{j-1}, y_{j-1}) = \\log p_{x_j|y_j} + \\log q_{y_j|y_{j-1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the end we get,\n",
    "$$\n",
    "\\mathbf{y}^{\\max} = \\argmax_\\mathbf{y} \\sum_j \\mathrm{trans}(x_j, y_j, y_{j-1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Viterbi Algorithm\n",
    "> The Viterbi Algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states – called the Viterbi path – that results in a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (from Wikipedia).\n",
    "\n",
    "__objective__: find $\\mathbf{y}$ such that satisfy, $\\mathbf{y}^{\\max} = \\argmax_\\mathbf{y} \\sum_j \\mathrm{trans}(x_j, y_j, y_{j-1})$.\n",
    "\n",
    "This algorithm consists of two parts which will be discussed in the following slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\begin{cases}\n",
    "t(j, y_j) = \\max_{y_{j-1}} [\\mathrm{trans}(x_j, y_j, y_{j-1}) + t(j-1, y_{j-1})] \\\\\n",
    "s(j, y_j) = \\argmax_{y_{j-1}} [\\mathrm{trans}(x_j, y_j, y_{j-1}) + t(j-1, y_{j-1})]\n",
    "\\end{cases}\n",
    "\\Leftrightarrow\n",
    "\\begin{cases}\n",
    "s(j, y_j) = \\argmax_{y_{j-1}} [\\mathrm{trans}(x_j, y_j, y_{j-1}) + t(j-1, y_{j-1})] \\\\\n",
    "t(j, y_j) = \\mathrm{trans}(x_j, y_j, s(j, y_j)) + t(j-1, s(j, y_j))\n",
    "\\end{cases}\n",
    "\\end{align} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::#74) (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag: a current tag, ptag: a previous tag\n",
    "trans_ = (pxy) -> (pyy) -> (word) -> (tag) -> (ptag) -> log(pxy(tag)(word)) + log(pyy(ptag)(tag))\n",
    "# # equivalent efficient yet bit complex form\n",
    "# trans_ = (pxy) -> (pyy) -> function (tag)\n",
    "#     px_ = pxy(tag)\n",
    "#     function (ptag)\n",
    "#         second = log(pyy(ptag)(tag))\n",
    "#         (word) -> log(px_(word)) + second\n",
    "#     end\n",
    "# end\n",
    "# @test trans_(tpxy)(tpyy)(\"i\")(\"AT\")(\"BT\") == -1.0986122886681098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "viterbi_fit (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi_fit(words, tags) = pxy_(nxy_(words, tags))(unique(words)), pyy_(nyy_(words, tags))(unique(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "viterbi_forward (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@inline function viterbi_forward(pxy, pyy, words, uniq_tags)\n",
    "    trans = trans_(pxy)(pyy)\n",
    "    T = zeros(Float64, length(words), length(uniq_tags)); S = zeros(Int64, length(words), length(uniq_tags))\n",
    "    for j in 1:length(uniq_tags) T[1, j] = log(pxy(uniq_tags[j])(words[1])) end\n",
    "    for i in 2:length(words)\n",
    "        for j in 1:length(uniq_tags)\n",
    "            (T[i, j], S[i, j]) = findmax([trans(words[i])(uniq_tags[j])(uniq_tags[k])+T[i-1, k] for k in 1:length(uniq_tags)])\n",
    "        end\n",
    "    end\n",
    "    return S, T\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "viterbi_backword (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@inline function viterbi_backword(T, S, uniq_tags, words)\n",
    "    _, j = findmax(T[end, :])\n",
    "    optimal_tags = []\n",
    "    push!(optimal_tags, uniq_tags[j])\n",
    "    for i in length(words):-1:2\n",
    "        push!(optimal_tags, uniq_tags[S[i, j]])\n",
    "        j = S[i, j]\n",
    "    end\n",
    "    return flipdim(optimal_tags, 1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0 0 … 0 0; 1 1 … 4 1; … ; 1 1 … 4 1; 1 1 … 1 5], [0.0 -Inf … -Inf -Inf; -Inf 0.0 … 0.0 -Inf; … ; -Inf -Inf … 0.0 -Inf; -Inf -Inf … -Inf 0.0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twords = [\"i\", \"am\", \"ai\", \"i\", \"am\", \"governor\"]; tuniq_words = unique(twords)\n",
    "ttags = [\"AT\", \"BT\", \"CT\", \"DT\", \"ET\", \"FT\"]; tuniq_tags = unique(ttags)\n",
    "pxy, pyy = viterbi_fit(twords, ttags)\n",
    "S, T = viterbi_forward(pxy, pyy, twords, unique(ttags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×6 Array{Float64,2}:\n",
       "    0.0  -Inf    -Inf       0.0  -Inf    -Inf  \n",
       " -Inf       0.0  -Inf    -Inf       0.0  -Inf  \n",
       " -Inf    -Inf       0.0  -Inf    -Inf    -Inf  \n",
       " -Inf    -Inf    -Inf       0.0  -Inf    -Inf  \n",
       " -Inf    -Inf    -Inf    -Inf       0.0  -Inf  \n",
       " -Inf    -Inf    -Inf    -Inf    -Inf       0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×6 Array{Int64,2}:\n",
       " 0  0  0  0  0  0\n",
       " 1  1  1  1  4  1\n",
       " 1  1  2  1  1  1\n",
       " 1  1  1  3  1  1\n",
       " 1  1  1  1  4  1\n",
       " 1  1  1  1  1  5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{Any,1}:\n",
       " \"AT\"\n",
       " \"BT\"\n",
       " \"CT\"\n",
       " \"DT\"\n",
       " \"ET\"\n",
       " \"FT\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_tags = viterbi_backword(T, S, unique(ttags), twords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Try the simplest example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from, til = 1, 250\n",
    "xtrain = X_train_[from:til]; ytrain = y_train_[from:til]\n",
    "pxy, pyy = viterbi_fit(xtrain, ytrain)\n",
    "uniq_tags = unique(ytrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: both ScikitLearn and DataFrames export \"fit!\"; uses of it in module Main must be qualified\n",
      "WARNING: both ScikitLearn and DataFrames export \"predict\"; uses of it in module Main must be qualified\n",
      "WARNING: both ScikitLearn and DataFrames export \"sample\"; uses of it in module Main must be qualified\n"
     ]
    }
   ],
   "source": [
    "from, til = 1, 10\n",
    "xtest = X_train_[from:til]; ytest = y_train_[from:til];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain = String[\"it\", \"urged\", \"that\", \"the\", \"city\", \"``\", \"take\", \"steps\", \"to\", \"remedy\", \"''\", \"this\", \"problem\", \"the\", \"controversial\", \"remark\", \"was\", \"first\", \"made\", \"sunday\", \"by\", \"hughes\", \"at\", \"a\", \"westfield\", \"young\", \"democratic\", \"club\", \"cocktail\", \"party\", \"at\", \"the\", \"scotch\", \"plains\", \"country\", \"club\", \"he\", \"said\", \"he\", \"was\", \"``\", \"confessing\", \"that\", \"i\", \"was\", \"a\", \"member\", \"of\", \"the\", \"socialist\", \"party\", \"in\", \"1910\", \"''\", \"the\", \"new\", \"year\", \"might\", \"see\", \"some\", \"house-cleaning\", \",\", \"either\", \"genuine\", \"or\", \"token\", \",\", \"depending\", \"upon\", \"developments\", \",\", \"to\", \"give\", \"davis\", \"an\", \"opportunity\", \"to\", \"combat\", \"some\", \"of\", \"these\", \"criticisms\", \"the\", \"jury\", \"said\", \"it\", \"did\", \"find\", \"that\", \"many\", \"of\", \"georgia's\", \"registration\", \"and\", \"election\", \"laws\", \"``\", \"are\", \"outmoded\", \"or\", \"inadequate\", \"and\", \"often\", \"ambiguous\", \"''\", \"wagner\", \"replied\", \",\", \"``\", \"can't\", \"you\", \"just\", \"see\", \"the\", \"headline\", \":\", \"'\", \"city\", \"hooked\", \"for\", \"\\$172,000\", \"'\", \"''\", \"?\", \"?\", \"'\", \"know\", \"enough\", \"to\", \"sue\", \"'\", \"berger\", \"insisted\", \"that\", \"``\", \"we\", \"know\", \"enough\", \"to\", \"sue\", \"for\", \"the\", \"full\", \"amount\", \"''\", \"attorney\", \"dwight\", \"l.\", \"schwab\", \",\", \"in\", \"behalf\", \"of\", \"defendant\", \"philip\", \"weinstein\", \",\", \"argued\", \"there\", \"is\", \"no\", \"evidence\", \"linking\", \"weinstein\", \"to\", \"the\", \"conspiracy\", \",\", \"but\", \"judge\", \"powell\", \"declared\", \"this\", \"is\", \"a\", \"matter\", \"for\", \"the\", \"jury\", \"to\", \"decide\", \"one\", \"of\", \"these\", \"men\", \"is\", \"former\", \"fire\", \"chief\", \"john\", \"a.\", \"laughlin\", \",\", \"he\", \"said\", \"there\", \"is\", \"a\", \"tangible\", \"feeling\", \"in\", \"the\", \"air\", \"of\", \"revulsion\", \"toward\", \"politics\", \"he\", \"said\", \"he\", \"would\", \"not\", \"be\", \"surprised\", \"if\", \"some\", \"of\", \"the\", \"more\", \"than\", \"30\", \"members\", \"of\", \"the\", \"group\", \"are\", \"interested\", \"in\", \"running\", \"on\", \"the\", \"required\", \"non-partisan\", \"ballot\", \"for\", \"posts\", \"on\", \"the\", \"charter\", \"commission\", \"it\", \"is\", \"a\", \"desperate\", \"effort\", \"to\", \"prop\", \"up\", \"a\", \"sagging\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0 0 … 0 0; 1 1 … 1 1; … ; 1 1 … 1 1; 1 1 … 1 1], [-0.980829 -Inf … -Inf -Inf; -Inf -3.8712 … -Inf -Inf; … ; -Inf -Inf … -Inf -Inf; -Inf -Inf … -Inf -Inf])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show xtrain;\n",
    "S, T = viterbi_forward(pxy, pyy, xtest, uniq_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "S, T = viterbi_forward(pxy, pyy, xtest, uniq_tags);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_tags = Any[\"PPS\", \"VBD\", \"CS\", \"AT\", \"NN\", \"``\", \"VB\", \"NNS\", \"TO\", \"VB\"]\n",
      "ytest = String[\"PPS\", \"VBD\", \"CS\", \"AT\", \"NN\", \"``\", \"VB\", \"NNS\", \"TO\", \"VB\"]\n"
     ]
    }
   ],
   "source": [
    "optimal_tags = viterbi_backword(T, S, uniq_tags, xtest)\n",
    "@show optimal_tags;\n",
    "@show ytest;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So far, so good. Try another example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtest = String[\"it\", \"urged\", \"that\", \"the\", \"city\", \"``\", \"take\", \"steps\", \"to\", \"remedy\"]\n",
      "xtest2 = String[\"???\", \"urged\", \"that\", \"the\", \"city\", \"``\", \"take\", \"steps\", \"to\", \"remedy\"]\n"
     ]
    }
   ],
   "source": [
    "@show xtest\n",
    "xtest2 = xtest; xtest2[1] = \"???\"\n",
    "@show xtest2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_tags = Any[\"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\"]\n",
      "ytest = String[\"PPS\", \"VBD\", \"CS\", \"AT\", \"NN\", \"``\", \"VB\", \"NNS\", \"TO\", \"VB\"]\n"
     ]
    }
   ],
   "source": [
    "S, T = viterbi_forward(pxy, pyy, xtest, uniq_tags)\n",
    "optimal_tags = viterbi_backword(T, S, uniq_tags, xtest)\n",
    "@show optimal_tags;\n",
    "@show ytest;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"http://i0.kym-cdn.com/entries/icons/original/000/002/252/NoMeGusta.jpg\" alt=\"\" width=\"500px\" height=\"500px\">\n",
    "http://i0.kym-cdn.com/entries/icons/original/000/002/252/NoMeGusta.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We may use possible (messy) workaround shown below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::#96) (generic function with 1 method)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nxy__ = (words, tags) -> word -> tag -> sum((words .== word) .& (tags .== tag)) + 1\n",
    "# n_{tag1 | tag2} in other words, y = tag1; y' = tag2\n",
    "nyy__ = (words, tags) -> tag1 -> tag2 -> sum((tags .== tag1) .& (circshift(tags, 1) .== tag2)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "viterbi_fit_alt (generic function with 1 method)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi_fit_alt(words, tags) = pxy_(nxy__(words, tags))(unique(words)), pyy_(nyy__(words, tags))(unique(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_tags = Any[\"PPS\", \"VBD\", \"CS\", \"AT\", \"NN\", \"IN\", \"AT\", \"NN\", \"TO\", \"VB\"]\n",
      "ytest = String[\"PPS\", \"VBD\", \"CS\", \"AT\", \"NN\", \"``\", \"VB\", \"NNS\", \"TO\", \"VB\"]\n"
     ]
    }
   ],
   "source": [
    "pxy, pyy = viterbi_fit_alt(xtrain, ytrain);\n",
    "S, T = viterbi_forward(pxy, pyy, xtest, uniq_tags)\n",
    "optimal_tags = viterbi_backword(T, S, uniq_tags, xtest)\n",
    "@show optimal_tags;\n",
    "@show ytest;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_tags = Any[\"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\"]\n",
      "testlabel = String[\"VBG\", \"IN\", \"PP\\$\", \"NN\", \"AT\", \"JJ\", \"NN\", \"MD\", \"VB\", \"DTI\", \"NN\"]\n"
     ]
    }
   ],
   "source": [
    "testdata = [\"contributing\", \"to\", \"its\", \"defeat\", \"the\", \"new\", \"year\", \"might\", \"see\", \"some\", \"house-cleaning\"]\n",
    "testlabel = [\"VBG\", \"IN\", \"PP\\$\", \"NN\", \"AT\", \"JJ\", \"NN\", \"MD\", \"VB\", \"DTI\", \"NN\"]\n",
    "S, T = viterbi_forward(pxy, pyy, testdata, uniq_tags)\n",
    "optimal_tags = viterbi_backword(T, S, uniq_tags, testdata)\n",
    "@show optimal_tags;\n",
    "@show testlabel;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_tags = Any[\"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\", \"PPS\"]\n",
      "testlabel = String[\"VBG\", \"IN\", \"PP\\$\", \"NN\", \"AT\", \"JJ\", \"NN\", \"MD\", \"VB\", \"DTI\", \"NN\"]\n"
     ]
    }
   ],
   "source": [
    "testdata = [\"???\", \"to\", \"its\", \"defeat\", \"the\", \"new\", \"year\", \"might\", \"see\", \"some\", \"house-cleaning\"]\n",
    "testlabel = [\"VBG\", \"IN\", \"PP\\$\", \"NN\", \"AT\", \"JJ\", \"NN\", \"MD\", \"VB\", \"DTI\", \"NN\"]\n",
    "S, T = viterbi_forward(pxy, pyy, testdata, uniq_tags)\n",
    "optimal_tags = viterbi_backword(T, S, uniq_tags, testdata)\n",
    "@show optimal_tags;\n",
    "@show testlabel;"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  },
  "nav_menu": {},
  "toc": {
   "nav_menu": {
    "height": "200px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
